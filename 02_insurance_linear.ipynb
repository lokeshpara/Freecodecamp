{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "02-insurance-linear.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "m2t3On6NLWkL",
        "colab_type": "text"
      },
      "source": [
        "# Insurance cost prediction using linear regression\n",
        "\n",
        "In this assignment we're going to use information like a person's age, sex, BMI, no. of children and smoking habit to predict the price of yearly medical bills. This kind of model is useful for insurance companies to determine the yearly insurance premium for a person. The dataset for this problem is taken from: https://www.kaggle.com/mirichoi0218/insurance\n",
        "\n",
        "\n",
        "We will create a model with the following steps:\n",
        "1. Download and explore the dataset\n",
        "2. Prepare the dataset for training\n",
        "3. Create a linear regression model\n",
        "4. Train the model to fit the data\n",
        "5. Make predictions using the trained model\n",
        "\n",
        "\n",
        "This assignment builds upon the concepts from the first 2 lectures. It will help to review these Jupyter notebooks:\n",
        "- PyTorch basics: https://jovian.ml/aakashns/01-pytorch-basics\n",
        "- Linear Regression: https://jovian.ml/aakashns/02-linear-regression\n",
        "- Logistic Regression: https://jovian.ml/aakashns/03-logistic-regression\n",
        "- Linear regression (minimal): https://jovian.ml/aakashns/housing-linear-minimal\n",
        "- Logistic regression (minimal): https://jovian.ml/aakashns/mnist-logistic-minimal\n",
        "\n",
        "As you go through this notebook, you will find a **???** in certain places. Your job is to replace the **???** with appropriate code or values, to ensure that the notebook runs properly end-to-end . In some cases, you'll be required to choose some hyperparameters (learning rate, batch size etc.). Try to experiment with the hypeparameters to get the lowest loss.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziqoHIoyLWkN",
        "colab_type": "code",
        "outputId": "44403ca9-d4a7-476c-8219-869dbf475465",
        "colab": {}
      },
      "source": [
        "# Uncomment and run the commands below if imports fail\n",
        "!conda install numpy pytorch torchvision cpuonly -c pytorch -y\n",
        "!pip install matplotlib --upgrade --quiet\n",
        "!pip install jovian --upgrade --quiet\n",
        "!pip install wheel\n",
        "!pip install pandas"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting package metadata (current_repodata.json): done\n",
            "Solving environment: done\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "  current version: 4.8.2\n",
            "  latest version: 4.8.3\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base conda\n",
            "\n",
            "\n",
            "\n",
            "# All requested packages already installed.\n",
            "\n",
            "Requirement already satisfied: wheel in /srv/conda/envs/notebook/lib/python3.7/site-packages (0.34.2)\n",
            "Requirement already satisfied: pandas in /srv/conda/envs/notebook/lib/python3.7/site-packages (1.0.4)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from pandas) (1.18.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from pandas) (2020.1)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UC56Za0cLWkf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import jovian\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "from torchvision.datasets.utils import download_url\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xu4N06eSLWkk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "project_name='02-insurance-linear-regression' # will be used by jovian.commit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEFglzqTLWko",
        "colab_type": "text"
      },
      "source": [
        "## Step 1: Download and explore the data\n",
        "\n",
        "Let us begin by downloading the data. We'll use the `download_url` function from PyTorch to get the data as a CSV (comma-separated values) file. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "id": "IJFICxvsLWkq",
        "colab_type": "code",
        "outputId": "bed9471f-cb29-4ba8-fdd7-7f50785b6fee",
        "colab": {}
      },
      "source": [
        "DATASET_URL = \"https://hub.jovian.ml/wp-content/uploads/2020/05/insurance.csv\"\n",
        "DATA_FILENAME = \"insurance.csv\"\n",
        "download_url(DATASET_URL, '.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using downloaded and verified file: ./insurance.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RusDvZkuLWkw",
        "colab_type": "text"
      },
      "source": [
        "To load the dataset into memory, we'll use the `read_csv` function from the `pandas` library. The data will be loaded as a Pandas dataframe. See this short tutorial to learn more: https://data36.com/pandas-tutorial-1-basics-reading-data-files-dataframes-data-selection/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDEMrULBLWkx",
        "colab_type": "code",
        "outputId": "ec8918c6-bcc5-46a5-b88f-49c3affa3ea9",
        "colab": {}
      },
      "source": [
        "dataframe_raw = pd.read_csv(DATA_FILENAME)\n",
        "dataframe_raw.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>charges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>female</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>southwest</td>\n",
              "      <td>16884.92400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>male</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1725.55230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>male</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>4449.46200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>male</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>21984.47061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>male</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>3866.85520</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age     sex     bmi  children smoker     region      charges\n",
              "0   19  female  27.900         0    yes  southwest  16884.92400\n",
              "1   18    male  33.770         1     no  southeast   1725.55230\n",
              "2   28    male  33.000         3     no  southeast   4449.46200\n",
              "3   33    male  22.705         0     no  northwest  21984.47061\n",
              "4   32    male  28.880         0     no  northwest   3866.85520"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Q8F9qk9LWk2",
        "colab_type": "text"
      },
      "source": [
        "We're going to do a slight customization of the data, so that you every participant receives a slightly different version of the dataset. Fill in your name below as a string (enter at least 5 characters)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Si04FCexLWk3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "your_name = \"lokesh\" # at least 5 characters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxSA4kcDLWk9",
        "colab_type": "text"
      },
      "source": [
        "The `customize_dataset` function will customize the dataset slightly using your name as a source of random numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wWckHoXLWk-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def customize_dataset(dataframe_raw, rand_str):\n",
        "    dataframe = dataframe_raw.copy(deep=True)\n",
        "    # drop some rows\n",
        "    dataframe = dataframe.sample(int(0.95*len(dataframe)), random_state=int(ord(rand_str[0])))\n",
        "    # scale input\n",
        "    dataframe.bmi = dataframe.bmi * ord(rand_str[1])/100.\n",
        "    # scale target\n",
        "    dataframe.charges = dataframe.charges * ord(rand_str[2])/100.\n",
        "    # drop column\n",
        "    if ord(rand_str[3]) % 2 == 1:\n",
        "        dataframe = dataframe.drop(['region'], axis=1)\n",
        "    return dataframe"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "249JIkrnLWlC",
        "colab_type": "code",
        "outputId": "ba04e300-dd93-41d0-c0c8-71c4444d4685",
        "colab": {}
      },
      "source": [
        "dataframe = customize_dataset(dataframe_raw, your_name)\n",
        "dataframe.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>charges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>469</th>\n",
              "      <td>18</td>\n",
              "      <td>female</td>\n",
              "      <td>26.73990</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>2355.173897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>22</td>\n",
              "      <td>male</td>\n",
              "      <td>41.75820</td>\n",
              "      <td>1</td>\n",
              "      <td>yes</td>\n",
              "      <td>39766.725266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>517</th>\n",
              "      <td>45</td>\n",
              "      <td>male</td>\n",
              "      <td>33.84945</td>\n",
              "      <td>2</td>\n",
              "      <td>no</td>\n",
              "      <td>9002.405464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>62</td>\n",
              "      <td>female</td>\n",
              "      <td>43.51200</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>14413.820200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>60</td>\n",
              "      <td>female</td>\n",
              "      <td>27.22830</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>13513.989469</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     age     sex       bmi  children smoker       charges\n",
              "469   18  female  26.73990         1     no   2355.173897\n",
              "82    22    male  41.75820         1    yes  39766.725266\n",
              "517   45    male  33.84945         2     no   9002.405464\n",
              "499   62  female  43.51200         0     no  14413.820200\n",
              "48    60  female  27.22830         0     no  13513.989469"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wv6-O07mLWlF",
        "colab_type": "text"
      },
      "source": [
        "Let us answer some basic questions about the dataset. \n",
        "\n",
        "\n",
        "**Q: How many rows does the dataset have?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yv4J5tuLWlG",
        "colab_type": "code",
        "outputId": "32154ff9-cea9-40b2-b51c-3becab497653",
        "colab": {}
      },
      "source": [
        "num_rows = dataframe.shape[0]\n",
        "print(num_rows)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1271\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EQ3IwH8LWlK",
        "colab_type": "text"
      },
      "source": [
        "**Q: How many columns doe the dataset have**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPYmsDSJLWlL",
        "colab_type": "code",
        "outputId": "e36f9a71-e15a-4dee-fb62-ab13f3d98387",
        "colab": {}
      },
      "source": [
        "num_cols = dataframe.shape[1]\n",
        "print(num_cols)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNMUGlwzLWlO",
        "colab_type": "text"
      },
      "source": [
        "**Q: What are the column titles of the input variables?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBCbe17yLWlO",
        "colab_type": "code",
        "outputId": "9369fd69-a281-4321-e374-cc5b47128166",
        "colab": {}
      },
      "source": [
        "input_cols = list(dataframe.columns.values)\n",
        "# input_cols = [???]\n",
        "input_cols.remove('charges')\n",
        "print(input_cols)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['age', 'sex', 'bmi', 'children', 'smoker']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_fVU1H4LWlR",
        "colab_type": "text"
      },
      "source": [
        "**Q: Which of the input columns are non-numeric or categorial variables ?**\n",
        "\n",
        "Hint: `sex` is one of them. List the columns that are not numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fi-WZlh3LWlS",
        "colab_type": "code",
        "outputId": "a168839f-7cc6-4d06-e37b-c8a909a41484",
        "colab": {}
      },
      "source": [
        "categorical_cols = dataframe.select_dtypes('object').columns.to_list()\n",
        "print(categorical_cols)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['sex', 'smoker']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUbMwaRoLWlU",
        "colab_type": "text"
      },
      "source": [
        "**Q: What are the column titles of output/target variable(s)?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ol2Nkg5LWlV",
        "colab_type": "code",
        "outputId": "8a0cf177-13de-4150-d7e4-368778d5a8b5",
        "colab": {}
      },
      "source": [
        "output_cols = [dataframe.columns[5]]\n",
        "print(output_cols)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['charges']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLdHhPwNLWlY",
        "colab_type": "text"
      },
      "source": [
        "**Q: (Optional) What is the minimum, maximum and average value of the `charges` column? Can you show the distribution of values in a graph?**\n",
        "Use this data visualization cheatsheet for referece: https://jovian.ml/aakashns/dataviz-cheatsheet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6C1GYMgLWlZ",
        "colab_type": "code",
        "outputId": "233a21ee-d549-4b6e-99ea-6b9d129924d4",
        "colab": {}
      },
      "source": [
        "# Write your answer here\n",
        "print(dataframe['charges'].min())\n",
        "print(dataframe['charges'].max())\n",
        "\n",
        "!pip install seaborn\n",
        "import seaborn as sns\n",
        "\n",
        "plt.title(\"Distribution of Charges\")\n",
        "sns.distplot(dataframe.charges, kde=False);"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1200.4050730000001\n",
            "68234.3579707\n",
            "Requirement already satisfied: seaborn in /srv/conda/envs/notebook/lib/python3.7/site-packages (0.10.1)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from seaborn) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from seaborn) (1.18.5)\n",
            "Requirement already satisfied: matplotlib>=2.1.2 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from seaborn) (3.2.1)\n",
            "Requirement already satisfied: pandas>=0.22.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from seaborn) (1.0.4)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from matplotlib>=2.1.2->seaborn) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from matplotlib>=2.1.2->seaborn) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from matplotlib>=2.1.2->seaborn) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from matplotlib>=2.1.2->seaborn) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from pandas>=0.22.0->seaborn) (2020.1)\n",
            "Requirement already satisfied: six in /srv/conda/envs/notebook/lib/python3.7/site-packages (from cycler>=0.10->matplotlib>=2.1.2->seaborn) (1.15.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEWCAYAAACOv5f1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAa6UlEQVR4nO3df7xVdZ3v8dc7/JWCAnIul1EQMarBuYV6ksxyLJ1UMrV5XB3QUTS75M3m1s1u449KpztWo2mNt0nF0QFN8EdkWmMWMZZWV+xAqOCPBASDEA6Y4q+8Ap/7x/oeXRw3nH3O3puzN9/38/HYj7P2d631XZ9z2Lz32t+19lqKCMzMLC9v6e8CzMxs+3P4m5llyOFvZpYhh7+ZWYYc/mZmGXL4m5llyOFvvSbpGklfqlNfoyS9KGlAev5zSZ+oR9+pvx9LmlKv/nqx3X+UtE7SM31cf7mko+tdl1kXh79tIYXOK5JekPScpF9LOkfS66+ViDgnIv53lX1tM8Ai4umIGBgRm+pQ+yWSvtut/+MiYkatffeyjlHAecC4iPjPW1lmT0nfkvR0evNbmp4P2561Wr4c/lbJRyNiELAf8HXg74Hr670RSTvVu88mMQpYHxFrK82UtAswFzgQOBbYEzgMWA8cWs9CVPD/c3uziPDDj9cfwHLg6G5thwKbgb9Iz6cD/5imhwE/Ap4DngXup9ipuCmt8wrwIvAFYDQQwNnA08B9pbadUn8/B74GPAhsAO4EhqZ5RwIrK9VLEaL/D3gtbe+hUn+fSNNvAb4IrADWAjcCe6V5XXVMSbWtAy7axt9pr7R+Z+rvi6n/o9PvvDnVMb3Cup8A1gADe/h3+DzwMPA8cCuwW5o3JP3NO4E/pul9S+v+HLgU+FWq5W3Ah4EnUl/fAX7R9XdJ63wceCz19xNgv9Qu4Jvp77UBeKTrdeBHaz+8R2A9iogHgZXAByrMPi/NawOGAxcWq8TpFCH60SiGdS4rrfOXwJ8Dx2xlk2dQhNEIYCNwVRU13gN8Fbg1be/dFRY7Mz0+CIwBBgLf7rbM+4F3AEcBX5b051vZ5P+heAMYk36fM4CzIuJnwHHAH1IdZ1ZY92jgnoh4sYdf6xSKN7X9gXel2qF4k/k3ik9moygCvvvvcTowFRhEEfjfAy4A9qZ4E3hf14KSTqT4d/trin/H+4FZafaHgSOAt6ff9xSKTyjW4hz+Vq0/AEMrtL9GEdL7RcRrEXF/RPR0wahLIuKliHhlK/NviohFEfES8CXglK4DwjU6DbgyIpal4L0AmNRt+OkfIuKViHgIeAh405tIqmUScEFEvBARy4ErKAK3GnsDq6tY7qqI+ENEPAv8EBgPEBHrI2J2RLwcES9Q7OX/Zbd1p0fE4ojYSPFmtDgivp+eXwWUD0SfA3wtIh5L878KjJe0H8W/7yDgnYDSMtXUbk3O4W/V2odiWKe7y4ElwE8lLZN0fhV9/b4X81cAO1MML9Xqz1J/5b53ovjE0qUcii9TfDrobliqqXtf+1RZx3qKN8yeVKxF0u6SrpW0QtIGiuGzwd3eIMt/wz8rP09vzitL8/cD/jkd4O8avhOwT0T8B8Wnin8B1kqaJmnPKn9Pa2IOf+uRpPdQBNsvu89Le77nRcQY4ATgc5KO6pq9lS57+mQwsjQ9imLvcx3wErB7qa4BFMMU1fb7B4qgK/e9kWL8vTfWpZq697WqyvV/BhwjaY9ebrfLeRRDUxMiYk+KYRkoArtL+W+xGti364kklZ9TvDF8MiIGlx5vjYhfA0TEVRFxCDCOYvjnf/WxbmsiDn/bqnQ64vHALcB3I+KRCsscL+ltKVCeBzZRHOyEIlTH9GHTfytpnKTdga8A34viVNDfAbtJ+oiknSkOsu5aWm8NMHobZ7fMAv6npP0lDeSNYwQbe1NcquU24FJJg9LwyOeA7257zdfdRBG4syW9U9JbJO0t6UJJE6tYfxDFOP9zkoYCF/ew/L8D/0XSSWmI61ygfArqNcAFkg4EkLSXpJPT9HskTUh/75eAP/HGv6+1MIe/VfJDSS9QBNRFwJXAWVtZdizFnuyLwP8FvhMR96Z5XwO+mIYTPt+L7d9EcUbRM8BuwP8AiIjngU8B/0qxl/0SWw5f3J5+rpe0oEK/N6S+7wOeogiyv+tFXWV/l7a/jOIT0czUf48i4lWKg76PA3MozqJ5kGI4aV4VXXwLeCvFJ5AHgHt62N464GTgMoohp3FAB/Bqmn8H8E/ALWkYaRHFcQIoTkO9juIsoBVp/cur+T2tuannY3NmtiNJn4xWAqeV3qgtM97zN8uApGMkDZa0K8VpnaL41GCZcvib5eEwYCnFUNFHgZO2caqtZcDDPmZmGfKev5lZhpriwlrDhg2L0aNH93cZZmYtZf78+esioq3nJd+sKcJ/9OjRdHR09HcZZmYtRdKKnpeqzMM+ZmYZcvibmWXI4W9mliGHv5lZhhz+ZmYZcvibmWXI4W9mliGHv5lZhnoMf0kjJd0r6VFJiyV9JrUPlTRH0pPp55DULklXSVoi6WFJBzf6lzAzs96p5hu+G4HzImKBpEHAfElzgDOBuRHx9XTf1vOBv6e4CcTY9JgAXJ1+NszMeU9XtdypE0Y1sgwzs5bR455/RKyOiAVp+gXgMYr7uZ4IzEiLzQBOStMnAjdG4QGKG0tXc7NqMzPbTno15i9pNHAQxa3mhkfE6jTrGWB4mt6H4vZ/XVamtu59TZXUIamjs7Ozl2WbmVktqg7/dMPr2cBnI2JDeV4UNwXo1Y0BImJaRLRHRHtbW58uSmdmZn1UVfhL2pki+G+OiO+n5jVdwznp59rUvgoYWVp939RmZmZNopqzfQRcDzwWEVeWZt0FTEnTU4A7S+1npLN+3gs8XxoeMjOzJlDN2T6HA6cDj0hamNouBL4O3CbpbGAFcEqadzcwEVgCvAycVdeKzcysZj2Gf0T8EtBWZh9VYfkAzq2xLjMzayB/w9fMLEMOfzOzDDn8zcwy5PA3M8uQw9/MLEMOfzOzDDn8zcwy5PA3M8uQw9/MLEMOfzOzDDn8zcwy5PA3M8uQw9/MLEMOfzOzDDn8zcwy5PA3M8tQNbdxvEHSWkmLSm23SlqYHsu77vAlabSkV0rzrmlk8WZm1jfV3MZxOvBt4Mauhoj4m65pSVcAz5eWXxoR4+tVoJmZ1V81t3G8T9LoSvPSzd1PAT5U37LMzKyRah3z/wCwJiKeLLXtL+m3kn4h6QNbW1HSVEkdkjo6OztrLMPMzHqj1vCfDMwqPV8NjIqIg4DPATMl7VlpxYiYFhHtEdHe1tZWYxlmZtYbfQ5/STsBfw3c2tUWEa9GxPo0PR9YCry91iLNzKy+atnzPxp4PCJWdjVIapM0IE2PAcYCy2or0czM6q3HA76SZgFHAsMkrQQujojrgUlsOeQDcATwFUmvAZuBcyLi2fqW3Hcz5z1d9bKnThjVwErMzPpXNWf7TN5K+5kV2mYDs2svy8zMGsnf8DUzy5DD38wsQw5/M7MMOfzNzDLk8Dczy5DD38wsQw5/M7MMOfzNzDLk8Dczy5DD38wsQw5/M7MMOfzNzDLk8Dczy5DD38wsQw5/M7MMOfzNzDLk8Dczy1CP4S/pBklrJS0qtV0iaZWkhekxsTTvAklLJD0h6ZhGFW5mZn1XzZ7/dODYCu3fjIjx6XE3gKRxFPf2PTCt852uG7qbmVnz6DH8I+I+oNqbsJ8I3BIRr0bEU8AS4NAa6jMzswaoZcz/05IeTsNCQ1LbPsDvS8usTG1vImmqpA5JHZ2dnTWUYWZmvdXX8L8aOAAYD6wGruhtBxExLSLaI6K9ra2tj2WYmVlf9Cn8I2JNRGyKiM3AdbwxtLMKGFladN/UZmZmTaRP4S9pROnpx4CuM4HuAiZJ2lXS/sBY4MHaSjQzs3rbqacFJM0CjgSGSVoJXAwcKWk8EMBy4JMAEbFY0m3Ao8BG4NyI2NSY0s3MrK96DP+ImFyh+fptLH8pcGktRZmZWWP1GP65mjnv6aqWO3XCqAZXYmZWfw7/7chvKGbWLHxtHzOzDDn8zcwy5PA3M8uQx/xrVO04vplZM/Gev5lZhhz+ZmYZcvibmWXI4W9mliGHv5lZhhz+ZmYZcvibmWXI4W9mliGHv5lZhhz+ZmYZ6jH8Jd0gaa2kRaW2yyU9LulhSXdIGpzaR0t6RdLC9LimkcWbmVnfVLPnPx04tlvbHOAvIuJdwO+AC0rzlkbE+PQ4pz5lmplZPfUY/hFxH/Bst7afRsTG9PQBYN8G1GZmZg1SjzH/jwM/Lj3fX9JvJf1C0gfq0L+ZmdVZTZd0lnQRsBG4OTWtBkZFxHpJhwA/kHRgRGyosO5UYCrAqFG+baGZ2fbU5z1/SWcCxwOnRUQARMSrEbE+Tc8HlgJvr7R+REyLiPaIaG9ra+trGWZm1gd9Cn9JxwJfAE6IiJdL7W2SBqTpMcBYYFk9CjUzs/rpcdhH0izgSGCYpJXAxRRn9+wKzJEE8EA6s+cI4CuSXgM2A+dExLMVOzYzs37TY/hHxOQKzddvZdnZwOxaizIzs8byN3zNzDLk8Dczy5DD38wsQw5/M7MMOfzNzDLk8Dczy5DD38wsQw5/M7MMOfzNzDLk8Dczy5DD38wsQw5/M7MMOfzNzDLk8Dczy5DD38wsQw5/M7MM1XQDd2uMmfOernrZUyeMamAlZrajqmrPX9INktZKWlRqGyppjqQn088hqV2SrpK0RNLDkg5uVPFmZtY31Q77TAeO7dZ2PjA3IsYCc9NzgOMobtw+FpgKXF17mWZmVk9VhX9E3Ad0vxH7icCMND0DOKnUfmMUHgAGSxpRj2LNzKw+ajngOzwiVqfpZ4DhaXof4Pel5Vamti1ImiqpQ1JHZ2dnDWWYmVlv1eVsn4gIIHq5zrSIaI+I9ra2tnqUYWZmVaol/Nd0Deekn2tT+ypgZGm5fVObmZk1iVrC/y5gSpqeAtxZaj8jnfXzXuD50vCQmZk1garO85c0CzgSGCZpJXAx8HXgNklnAyuAU9LidwMTgSXAy8BZda7ZzMxqVFX4R8Tkrcw6qsKyAZxbS1FmZtZYvryDmVmGHP5mZhly+JuZZcjhb2aWIYe/mVmGHP5mZhly+JuZZcjhb2aWIYe/mVmGHP5mZhly+JuZZcjhb2aWIYe/mVmGHP5mZhly+JuZZcjhb2aWIYe/mVmGqrqTVyWS3gHcWmoaA3wZGAz8N6AztV8YEXf3uUIzM6u7Pod/RDwBjAeQNABYBdxBcc/eb0bEN+pSoZmZ1V29hn2OApZGxIo69WdmZg1Ur/CfBMwqPf+0pIcl3SBpSKUVJE2V1CGpo7Ozs9IiZmbWIDWHv6RdgBOA21PT1cABFENCq4ErKq0XEdMioj0i2tva2motw8zMeqEee/7HAQsiYg1ARKyJiE0RsRm4Dji0DtswM7M6qkf4T6Y05CNpRGnex4BFddiGmZnVUZ/P9gGQtAfwV8AnS82XSRoPBLC82zwzM2sCNYV/RLwE7N2t7fSaKjIzs4bzN3zNzDLk8Dczy5DD38wsQw5/M7MMOfzNzDLk8Dczy5DD38wsQw5/M7MMOfzNzDLk8Dczy5DD38wsQw5/M7MMOfzNzDLk8Dczy5DD38wsQw5/M7MM1XQzFwBJy4EXgE3AxoholzQUuBUYTXE3r1Mi4o+1bsvMzOqjXnv+H4yI8RHRnp6fD8yNiLHA3PTczMyaRKOGfU4EZqTpGcBJDdqOmZn1QT3CP4CfSpovaWpqGx4Rq9P0M8DwOmzHzMzqpOYxf+D9EbFK0n8C5kh6vDwzIkJSdF8pvVFMBRg1alQdyjAzs2rVvOcfEavSz7XAHcChwBpJIwDSz7UV1psWEe0R0d7W1lZrGWZm1gs1hb+kPSQN6poGPgwsAu4CpqTFpgB31rIdMzOrr1qHfYYDd0jq6mtmRNwj6TfAbZLOBlYAp9S4HTMzq6Oawj8ilgHvrtC+Hjiqlr7NzKxx/A1fM7MMOfzNzDJUj1M9rR/NnPd0VcudOsGn05rZG7znb2aWIYe/mVmGPOxjb+KhJLMdn/f8zcwy5PA3M8uQw9/MLEMOfzOzDPmAbyaqPYhrZnnwnr+ZWYYc/mZmGfKwj/WZvw9g1rq8529mliGHv5lZhhz+ZmYZ6nP4Sxop6V5Jj0paLOkzqf0SSaskLUyPifUr18zM6qGWA74bgfMiYkG6ift8SXPSvG9GxDdqL8/MzBqhz+EfEauB1Wn6BUmPAfvUqzDbcfTmC2Y+M8hs+6jLqZ6SRgMHAfOAw4FPSzoD6KD4dPDHCutMBaYCjBrl//BmPnXWtqeaD/hKGgjMBj4bERuAq4EDgPEUnwyuqLReREyLiPaIaG9ra6u1DDMz64Wawl/SzhTBf3NEfB8gItZExKaI2AxcBxxae5lmZlZPfR72kSTgeuCxiLiy1D4iHQ8A+BiwqLYSzVqXL6hnzaqWMf/DgdOBRyQtTG0XApMljQcCWA58sqYKzcys7mo52+eXgCrMurvv5ZiZ2fbgC7tZS+rv00c9nGOtzuFvTcWharZ9OPzNWkx/f+qxHYPD32wH1ogvjvnLaDsGX9XTzCxDDn8zsww5/M3MMuQxfzPzWVYZ8p6/mVmGHP5mZhly+JuZZcjhb2aWIR/wtR2ev5Rk9mYOf7PEZ7xYThz+ZtYQvgZRc/OYv5lZhhz+ZmYZalj4SzpW0hOSlkg6v1HbMTOz3mvImL+kAcC/AH8FrAR+I+muiHi0Edszs9a2o52R1QrHOxp1wPdQYElELAOQdAtwIuDwN7PtwmdvbVujwn8f4Pel5yuBCeUFJE0FpqanL0p6oop+hwHr6lLh9tOKNUNr1t2KNUNr1t0vNZ9WexdN97eu4nfaVs379XW7/XaqZ0RMA6b1Zh1JHRHR3qCSGqIVa4bWrLsVa4bWrLsVa4bWrLtRNTfqgO8qYGTp+b6pzczMmkCjwv83wFhJ+0vaBZgE3NWgbZmZWS81ZNgnIjZK+jTwE2AAcENELK5D170aJmoSrVgztGbdrVgztGbdrVgztGbdDalZEdGIfs3MrIn5G75mZhly+JuZZahlwr+/Lxch6QZJayUtKrUNlTRH0pPp55DULklXpVoflnRwaZ0pafknJU0ptR8i6ZG0zlWSVIeaR0q6V9KjkhZL+kyz1y1pN0kPSnoo1fwPqX1/SfPSdm5NJxIgadf0fEmaP7rU1wWp/QlJx5TaG/ZakjRA0m8l/agV6pa0PP37LZTUkdqa9vVR6newpO9JelzSY5IOa+a6Jb0j/Y27HhskfbZfa46Ipn9QHDReCowBdgEeAsZt5xqOAA4GFpXaLgPOT9PnA/+UpicCPwYEvBeYl9qHAsvSzyFpekia92BaVmnd4+pQ8wjg4DQ9CPgdMK6Z6079DEzTOwPzUv+3AZNS+zXAf0/TnwKuSdOTgFvT9Lj0OtkV2D+9fgY0+rUEfA6YCfwoPW/quoHlwLBubU37+ijVOAP4RJreBRjcCnWnvgcAz1B8Qavfat4uwVmHP9ZhwE9Kzy8ALuiHOkazZfg/AYxI0yOAJ9L0tcDk7ssBk4FrS+3XprYRwOOl9i2Wq2P9d1Jcb6kl6gZ2BxZQfDt8HbBT99cDxRllh6XpndJy6v4a6Vquka8liu+zzAU+BPwo1dHUdVM5/Jv69QHsBTxFOmGlVeou9fdh4Ff9XXOrDPtUulzEPv1US9nwiFidpp8BhqfprdW7rfaVFdrrJg0rHESxJ93Udaehk4XAWmAOxR7vcxGxscJ2Xq8tzX8e2LsPv0s9fAv4ArA5Pd+7BeoO4KeS5qu45Ao0+euD4hNRJ/BvaYjtXyXt0QJ1d5kEzErT/VZzq4R/04vi7bYpz5uVNBCYDXw2IjaU5zVj3RGxKSLGU+xJHwq8s59L6pGk44G1ETG/v2vppfdHxMHAccC5ko4oz2zG1wfFJ6WDgasj4iDgJYohk9c1ad2kYz4nALd3n7e9a26V8G/Wy0WskTQCIP1cm9q3Vu+22vet0F4zSTtTBP/NEfH9VqkbICKeA+6lGPIYLKnrS4nl7bxeW5q/F7C+D79LrQ4HTpC0HLiFYujnn5u97ohYlX6uBe6geLNt9tfHSmBlRMxLz79H8WbQ7HVD8Sa7ICLWpOf9V3O9xrEa+aB4p19G8XGv62DXgf1Qx2i2HPO/nC0P1lyWpj/ClgdrHkztQynGKoekx1PA0DSv+8GaiXWoV8CNwLe6tTdt3UAbMDhNvxW4HzieYk+pfOD0U2n6XLY8cHpbmj6QLQ+cLqM40Nbw1xJwJG8c8G3auoE9gEGl6V8Dxzbz66NU+/3AO9L0JanmVqj7FuCsZvi/uF1Cs05/tIkUZ6ssBS7qh+3PAlYDr1HseZxNMUY7F3gS+FnpH0EUN7NZCjwCtJf6+TiwJD3KL4J2YFFa59t0O5jVx5rfT/Ex8mFgYXpMbOa6gXcBv001LwK+nNrHpBf3EopA3TW175aeL0nzx5T6uijV9QSlMx8a/Vpiy/Bv2rpTbQ+lx+KuPpv59VHqdzzQkV4nP6AIwqaum+INdj2wV6mt32r25R3MzDLUKmP+ZmZWRw5/M7MMOfzNzDLk8Dczy5DD38wsQw5/y4Kk6ZL+a3/XYdYsHP5mPUiX1/X/Fduh+AVtOyRJZ6TroD8k6abUfISkX0ta1vUpQNJASXMlLUjXQj8xtY9Wce38Gym+ODNS0pdS2y8lzZL0+bTsAZLuSRdHu1/SO1P7yZIWpRru64c/g9lW+UtetsORdCDFdWreFxHrJA0FrqT4huXfUFwo7q6IeFu6rs7uEbFB0jDgAWAsxbXWl6U+HpD0HuA6iq/P70xxqelrI+IbkuYC50TEk5ImAF+LiA9JegQ4NiJWSRocxbWKzJrCTj0vYtZyPgTcHhHrACLi2XRTox9ExGbgUUldl84V8NV0NcvNFJfB7Zq3IiIeSNOHA3dGxJ+AP0n6Ibx+xdT3AbeXbpy0a/r5K2C6pNuArovqmTUFh7/l5NXSdFdSn0ZxMblDIuK1dFXO3dK8l6ro8y0U1+wf331GRJyTPgl8BJgv6ZCIWN/n6s3qyGP+tiP6D+BkSXtDcU/abSy7F8V1+F+T9EGK4Z5KfgV8VMU9hgdSXGmUKO6P8JSkk9O2JOndafqAiJgXEV+muPnIyK30bbbdec/fdjgRsVjSpcAvJG2iuEro1twM/DCNz3cAj2+lz99IuoviKpJrKK60+HyafRpwtaQvUhwPuIXiSpmXSxpL8Sljbmozawo+4GtWJUkDI+JFSbsD9wFTI2JBf9dl1hfe8zer3jRJ4yiOCcxw8Fsr856/mVmGfMDXzCxDDn8zsww5/M3MMuTwNzPLkMPfzCxD/x/wNZou8cA36wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uA1-boOFLWld",
        "colab_type": "text"
      },
      "source": [
        "Remember to commit your notebook to Jovian after every step, so that you don't lose your work."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSTQRTLHLWle",
        "colab_type": "code",
        "outputId": "2fdcd70f-5082-4cfa-89f5-102cd8e13242",
        "colab": {}
      },
      "source": [
        "jovian.commit(project=project_name, environment=None)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[jovian] Attempting to save notebook..\u001b[0m\n",
            "[jovian] Updating notebook \"lokeshpara/02-insurance-linear-regression\" on https://jovian.ml/\u001b[0m\n",
            "[jovian] Uploading notebook..\u001b[0m\n",
            "[jovian] Attaching records (metrics, hyperparameters, dataset etc.)\u001b[0m\n",
            "[jovian] Committed successfully! https://jovian.ml/lokeshpara/02-insurance-linear-regression\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://jovian.ml/lokeshpara/02-insurance-linear-regression'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lM68V7JDLWlh",
        "colab_type": "text"
      },
      "source": [
        "## Step 2: Prepare the dataset for training\n",
        "\n",
        "We need to convert the data from the Pandas dataframe into a PyTorch tensors for training. To do this, the first step is to convert it numpy arrays. If you've filled out `input_cols`, `categorial_cols` and `output_cols` correctly, this following function will perform the conversion to numpy arrays."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isPRBrWGLWlh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dataframe_to_arrays(dataframe):\n",
        "    # Make a copy of the original dataframe\n",
        "    dataframe1 = dataframe.copy(deep=True)\n",
        "    # Convert non-numeric categorical columns to numbers\n",
        "    for col in categorical_cols:\n",
        "        dataframe1[col] = dataframe1[col].astype('category').cat.codes\n",
        "    # Extract input & outupts as numpy arrays\n",
        "    inputs_array = dataframe1[input_cols].to_numpy()\n",
        "    targets_array = dataframe1[output_cols].to_numpy()\n",
        "    return inputs_array, targets_array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dfa4sn_nLWlk",
        "colab_type": "text"
      },
      "source": [
        "Read through the [Pandas documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/categorical.html) to understand how we're converting categorical variables into numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YKFWUrYLWlk",
        "colab_type": "code",
        "outputId": "75657c27-203c-4114-d5df-8744585b9cd0",
        "colab": {}
      },
      "source": [
        "inputs_array, targets_array = dataframe_to_arrays(dataframe)\n",
        "inputs_array, targets_array"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[18.     ,  0.     , 26.7399 ,  1.     ,  0.     ],\n",
              "        [22.     ,  1.     , 41.7582 ,  1.     ,  1.     ],\n",
              "        [45.     ,  1.     , 33.84945,  2.     ,  0.     ],\n",
              "        ...,\n",
              "        [26.     ,  0.     , 37.962  ,  2.     ,  0.     ],\n",
              "        [23.     ,  1.     , 36.1416 ,  0.     ,  0.     ],\n",
              "        [31.     ,  0.     , 28.638  ,  2.     ,  0.     ]]),\n",
              " array([[ 2355.173897 ],\n",
              "        [39766.725266 ],\n",
              "        [ 9002.4054635],\n",
              "        ...,\n",
              "        [ 4267.08082  ],\n",
              "        [ 1951.985378 ],\n",
              "        [ 5280.13435  ]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzpEMLSKLWln",
        "colab_type": "text"
      },
      "source": [
        "**Q: Convert the numpy arrays `inputs_array` and `targets_array` into PyTorch tensors. Make sure that the data type is `torch.float32`.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXn4R53HLWln",
        "colab_type": "code",
        "outputId": "a496d3e5-6fda-4b13-db78-3361d5ebf162",
        "colab": {}
      },
      "source": [
        "inputs = torch.from_numpy(inputs_array).type(torch.float32)\n",
        "targets = torch.from_numpy(targets_array).type(torch.float32)\n",
        "inputs, targets"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[18.0000,  0.0000, 26.7399,  1.0000,  0.0000],\n",
              "         [22.0000,  1.0000, 41.7582,  1.0000,  1.0000],\n",
              "         [45.0000,  1.0000, 33.8494,  2.0000,  0.0000],\n",
              "         ...,\n",
              "         [26.0000,  0.0000, 37.9620,  2.0000,  0.0000],\n",
              "         [23.0000,  1.0000, 36.1416,  0.0000,  0.0000],\n",
              "         [31.0000,  0.0000, 28.6380,  2.0000,  0.0000]]),\n",
              " tensor([[ 2355.1738],\n",
              "         [39766.7266],\n",
              "         [ 9002.4053],\n",
              "         ...,\n",
              "         [ 4267.0811],\n",
              "         [ 1951.9854],\n",
              "         [ 5280.1343]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3LG0AhvLWlq",
        "colab_type": "code",
        "outputId": "92bdf69b-8d92-4889-a9a3-f46d3fd34f2c",
        "colab": {}
      },
      "source": [
        "inputs.dtype, targets.dtype"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.float32, torch.float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtrI5b7ULWls",
        "colab_type": "text"
      },
      "source": [
        "Next, we need to create PyTorch datasets & data loaders for training & validation. We'll start by creating a `TensorDataset`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWztmy5NLWlt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = TensorDataset(inputs, targets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBVYItVKLWlv",
        "colab_type": "text"
      },
      "source": [
        "**Q: Pick a number between `0.1` and `0.2` to determine the fraction of data that will be used for creating the validation set. Then use `random_split` to create training & validation datasets. **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARLUCvXSLWlw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_percent = 0.15 # between 0.1 and 0.2\n",
        "val_size = int(num_rows * val_percent)\n",
        "train_size = num_rows - val_size\n",
        "\n",
        "\n",
        "train_ds, val_ds = random_split(dataset, [train_size, val_size]) # Use the random_split function to split dataset into 2 parts of the desired length"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3q-gRWbLWlz",
        "colab_type": "text"
      },
      "source": [
        "Finally, we can create data loaders for training & validation.\n",
        "\n",
        "**Q: Pick a batch size for the data loader.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-GisaFHLWlz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZUkKCrdLWl2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = DataLoader(train_ds, batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Q3QbqfoLWl4",
        "colab_type": "text"
      },
      "source": [
        "Let's look at a batch of data to verify everything is working fine so far."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9N4INw9LWl5",
        "colab_type": "code",
        "outputId": "ae203b67-5668-4dc4-8dde-8b54478a51a2",
        "colab": {}
      },
      "source": [
        "for xb, yb in train_loader:\n",
        "    print(\"inputs:\", xb)\n",
        "    print(\"targets:\", yb)\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "inputs: tensor([[28.0000,  0.0000, 30.5250,  2.0000,  0.0000]])\n",
            "targets: tensor([[21590.1074]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSS6riZdLWl7",
        "colab_type": "text"
      },
      "source": [
        "Let's save our work by committing to Jovian."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyUUOlPjLWl7",
        "colab_type": "code",
        "outputId": "b4b76c30-3c36-46c3-f4d1-cb5130a1f681",
        "colab": {}
      },
      "source": [
        "jovian.commit(project=project_name, environment=None)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[jovian] Attempting to save notebook..\u001b[0m\n",
            "[jovian] Updating notebook \"lokeshpara/02-insurance-linear-regression\" on https://jovian.ml/\u001b[0m\n",
            "[jovian] Uploading notebook..\u001b[0m\n",
            "[jovian] Attaching records (metrics, hyperparameters, dataset etc.)\u001b[0m\n",
            "[jovian] Committed successfully! https://jovian.ml/lokeshpara/02-insurance-linear-regression\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://jovian.ml/lokeshpara/02-insurance-linear-regression'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbbZ-wlhLWmB",
        "colab_type": "text"
      },
      "source": [
        "## Step 3: Create a Linear Regression Model\n",
        "\n",
        "Our model itself is a fairly straightforward linear regression (we'll build more complex models in the next assignment). \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEL3SBHiLWmB",
        "colab_type": "code",
        "outputId": "ac31f6d3-f99c-4e6b-bec6-d0677f502515",
        "colab": {}
      },
      "source": [
        "input_size = len(input_cols)\n",
        "output_size = len(output_cols)\n",
        "print(input_size, output_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0iNEsNILWmE",
        "colab_type": "text"
      },
      "source": [
        "**Q: Complete the class definition below by filling out the constructor (`__init__`), `forward`, `training_step` and `validation_step` methods.**\n",
        "\n",
        "Hint: Think carefully about picking a good loss fuction (it's not cross entropy). Maybe try 2-3 of them and see which one works best. See https://pytorch.org/docs/stable/nn.functional.html#loss-functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9yqGfm6LWmF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class InsuranceModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(input_size, output_size)                  # fill this (hint: use input_size & output_size defined above)\n",
        "        \n",
        "    def forward(self, xb):\n",
        "        out = self.linear(xb)                            # fill this\n",
        "        return out\n",
        "    \n",
        "    def training_step(self, batch):\n",
        "        inputs, targets = batch \n",
        "        # Generate predictions\n",
        "        out = self(inputs)          \n",
        "        # Calcuate loss\n",
        "        loss = F.l1_loss(out, targets)                           # fill this\n",
        "        return loss\n",
        "    \n",
        "    def validation_step(self, batch):\n",
        "        inputs, targets = batch\n",
        "        # Generate predictions\n",
        "        out = self(inputs)\n",
        "        # Calculate loss\n",
        "        loss = F.l1_loss(out, targets)                          # fill this    \n",
        "        return {'val_loss': loss.detach()}\n",
        "        \n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
        "        return {'val_loss': epoch_loss.item()}\n",
        "    \n",
        "    def epoch_end(self, epoch, result, num_epochs):\n",
        "        # Print result every 20th epoch\n",
        "        if (epoch+1) % 20 == 0 or epoch == num_epochs-1:\n",
        "            print(\"Epoch [{}], val_loss: {:.4f}\".format(epoch+1, result['val_loss']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsmzezAgLWmH",
        "colab_type": "text"
      },
      "source": [
        "Let us create a model using the `InsuranceModel` class. You may need to come back later and re-run the next cell to reinitialize the model, in case the loss becomes `nan` or `infinity`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIWUMthrLWmI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = InsuranceModel()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDygEyCOLWmK",
        "colab_type": "text"
      },
      "source": [
        "Let's check out the weights and biases of the model using `model.parameters`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8LIm9zeLWmL",
        "colab_type": "code",
        "outputId": "fa32271a-b32b-4003-f07b-48d68c7f8df1",
        "colab": {}
      },
      "source": [
        "list(model.parameters())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[ 0.1601, -0.1478,  0.2225,  0.3565,  0.1471]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([0.3190], requires_grad=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvUSSodNLWmN",
        "colab_type": "text"
      },
      "source": [
        "One final commit before we train the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYoIXC0lLWmO",
        "colab_type": "code",
        "outputId": "d92d53f5-c8e5-4596-a769-9417975799be",
        "colab": {}
      },
      "source": [
        "jovian.commit(project=project_name, environment=None)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[jovian] Attempting to save notebook..\u001b[0m\n",
            "[jovian] Updating notebook \"lokeshpara/02-insurance-linear-regression\" on https://jovian.ml/\u001b[0m\n",
            "[jovian] Uploading notebook..\u001b[0m\n",
            "[jovian] Attaching records (metrics, hyperparameters, dataset etc.)\u001b[0m\n",
            "[jovian] Committed successfully! https://jovian.ml/lokeshpara/02-insurance-linear-regression\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://jovian.ml/lokeshpara/02-insurance-linear-regression'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1y-yKLfLWmR",
        "colab_type": "text"
      },
      "source": [
        "## Step 4: Train the model to fit the data\n",
        "\n",
        "To train our model, we'll use the same `fit` function explained in the lecture. That's the benefit of defining a generic training loop - you can use it for any problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpzYDK6GLWmS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, val_loader):\n",
        "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "    return model.validation_epoch_end(outputs)\n",
        "\n",
        "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
        "    history = []\n",
        "    optimizer = opt_func(model.parameters(), lr)\n",
        "    for epoch in range(epochs):\n",
        "        # Training Phase \n",
        "        for batch in train_loader:\n",
        "            loss = model.training_step(batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "        # Validation phase\n",
        "        result = evaluate(model, val_loader)\n",
        "        model.epoch_end(epoch, result, epochs)\n",
        "        history.append(result)\n",
        "    return history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGqbcOGsLWmV",
        "colab_type": "text"
      },
      "source": [
        "**Q: Use the `evaluate` function to calculate the loss on the validation set before training.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Lgo2ifZLWmV",
        "colab_type": "code",
        "outputId": "8bbbfc2f-7a29-4a3b-e156-70f8f267de57",
        "colab": {}
      },
      "source": [
        "result = evaluate(model, val_loader) # Use the the evaluate function\n",
        "print(result)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'val_loss': 12787.3271484375}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZP5oZN8ZLWmZ",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "We are now ready to train the model. You may need to run the training loop many times, for different number of epochs and with different learning rates, to get a good result. Also, if your loss becomes too large (or `nan`), you may have to re-initialize the model by running the cell `model = InsuranceModel()`. Experiment with this for a while, and try to get to as low a loss as possible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcth2bDnLWmZ",
        "colab_type": "text"
      },
      "source": [
        "**Q: Train the model 4-5 times with different learning rates & for different number of epochs.**\n",
        "\n",
        "Hint: Vary learning rates by orders of 10 (e.g. `1e-2`, `1e-3`, `1e-4`, `1e-5`, `1e-6`) to figure out what works."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FUf16ksLWma",
        "colab_type": "code",
        "outputId": "4ba66594-8cdd-450c-84a7-f723b28ff141",
        "colab": {}
      },
      "source": [
        "model = InsuranceModel()\n",
        "epochs = 1000\n",
        "lr = 1e-2\n",
        "history1 = fit(epochs, lr, model, train_loader, val_loader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [20], val_loss: 6130.4116\n",
            "Epoch [40], val_loss: 6107.7222\n",
            "Epoch [60], val_loss: 6084.4492\n",
            "Epoch [80], val_loss: 6071.4033\n",
            "Epoch [100], val_loss: 6062.5610\n",
            "Epoch [120], val_loss: 6054.7271\n",
            "Epoch [140], val_loss: 6039.0073\n",
            "Epoch [160], val_loss: 6037.6045\n",
            "Epoch [180], val_loss: 6019.7485\n",
            "Epoch [200], val_loss: 6009.2808\n",
            "Epoch [220], val_loss: 6016.0117\n",
            "Epoch [240], val_loss: 5995.3120\n",
            "Epoch [260], val_loss: 5995.3159\n",
            "Epoch [280], val_loss: 5972.4033\n",
            "Epoch [300], val_loss: 5970.6929\n",
            "Epoch [320], val_loss: 5951.7163\n",
            "Epoch [340], val_loss: 5942.0020\n",
            "Epoch [360], val_loss: 5940.1382\n",
            "Epoch [380], val_loss: 5923.3677\n",
            "Epoch [400], val_loss: 5912.5381\n",
            "Epoch [420], val_loss: 5912.3037\n",
            "Epoch [440], val_loss: 5900.2993\n",
            "Epoch [460], val_loss: 5890.6597\n",
            "Epoch [480], val_loss: 5885.9028\n",
            "Epoch [500], val_loss: 5873.7607\n",
            "Epoch [520], val_loss: 5852.9683\n",
            "Epoch [540], val_loss: 5843.3672\n",
            "Epoch [560], val_loss: 5833.0923\n",
            "Epoch [580], val_loss: 5822.9805\n",
            "Epoch [600], val_loss: 5815.0156\n",
            "Epoch [620], val_loss: 5806.2427\n",
            "Epoch [640], val_loss: 5793.7441\n",
            "Epoch [660], val_loss: 5785.0581\n",
            "Epoch [680], val_loss: 5773.5981\n",
            "Epoch [700], val_loss: 5766.5942\n",
            "Epoch [720], val_loss: 5754.1084\n",
            "Epoch [740], val_loss: 5744.3730\n",
            "Epoch [760], val_loss: 5734.1060\n",
            "Epoch [780], val_loss: 5739.4619\n",
            "Epoch [800], val_loss: 5714.9697\n",
            "Epoch [820], val_loss: 5706.1270\n",
            "Epoch [840], val_loss: 5697.4604\n",
            "Epoch [860], val_loss: 5684.9888\n",
            "Epoch [880], val_loss: 5675.5776\n",
            "Epoch [900], val_loss: 5687.1528\n",
            "Epoch [920], val_loss: 5658.2222\n",
            "Epoch [940], val_loss: 5646.2388\n",
            "Epoch [960], val_loss: 5640.6597\n",
            "Epoch [980], val_loss: 5631.4111\n",
            "Epoch [1000], val_loss: 5622.5586\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hsJ70CPLWmc",
        "colab_type": "code",
        "outputId": "5cec1539-07c2-4117-8900-7835027c924c",
        "colab": {}
      },
      "source": [
        "epochs = 1000\n",
        "lr = 1e-3\n",
        "history2 = fit(epochs, lr, model, train_loader, val_loader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [20], val_loss: 5617.4072\n",
            "Epoch [40], val_loss: 5615.5991\n",
            "Epoch [60], val_loss: 5615.7090\n",
            "Epoch [80], val_loss: 5615.0088\n",
            "Epoch [100], val_loss: 5612.7920\n",
            "Epoch [120], val_loss: 5612.3145\n",
            "Epoch [140], val_loss: 5611.6729\n",
            "Epoch [160], val_loss: 5611.5430\n",
            "Epoch [180], val_loss: 5610.7217\n",
            "Epoch [200], val_loss: 5607.8169\n",
            "Epoch [220], val_loss: 5606.9136\n",
            "Epoch [240], val_loss: 5606.9116\n",
            "Epoch [260], val_loss: 5605.5269\n",
            "Epoch [280], val_loss: 5604.8062\n",
            "Epoch [300], val_loss: 5603.9053\n",
            "Epoch [320], val_loss: 5602.0659\n",
            "Epoch [340], val_loss: 5602.0459\n",
            "Epoch [360], val_loss: 5601.7212\n",
            "Epoch [380], val_loss: 5601.3462\n",
            "Epoch [400], val_loss: 5598.5454\n",
            "Epoch [420], val_loss: 5597.5732\n",
            "Epoch [440], val_loss: 5596.6880\n",
            "Epoch [460], val_loss: 5596.8955\n",
            "Epoch [480], val_loss: 5594.4600\n",
            "Epoch [500], val_loss: 5593.5479\n",
            "Epoch [520], val_loss: 5593.5190\n",
            "Epoch [540], val_loss: 5592.7334\n",
            "Epoch [560], val_loss: 5591.5815\n",
            "Epoch [580], val_loss: 5590.5601\n",
            "Epoch [600], val_loss: 5589.1685\n",
            "Epoch [620], val_loss: 5588.7920\n",
            "Epoch [640], val_loss: 5587.1841\n",
            "Epoch [660], val_loss: 5586.2349\n",
            "Epoch [680], val_loss: 5585.7349\n",
            "Epoch [700], val_loss: 5585.1953\n",
            "Epoch [720], val_loss: 5583.8555\n",
            "Epoch [740], val_loss: 5583.4570\n",
            "Epoch [760], val_loss: 5581.6152\n",
            "Epoch [780], val_loss: 5581.7988\n",
            "Epoch [800], val_loss: 5581.5947\n",
            "Epoch [820], val_loss: 5580.1011\n",
            "Epoch [840], val_loss: 5577.6021\n",
            "Epoch [860], val_loss: 5576.6465\n",
            "Epoch [880], val_loss: 5576.7588\n",
            "Epoch [900], val_loss: 5575.6475\n",
            "Epoch [920], val_loss: 5574.4126\n",
            "Epoch [940], val_loss: 5573.7666\n",
            "Epoch [960], val_loss: 5573.6919\n",
            "Epoch [980], val_loss: 5571.0215\n",
            "Epoch [1000], val_loss: 5571.8369\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00J9QxLDLWmf",
        "colab_type": "code",
        "outputId": "c75350ab-d3cd-4d69-c6a9-5e7dab9cc375",
        "colab": {}
      },
      "source": [
        "epochs = 150\n",
        "lr = 1e-4\n",
        "history3 = fit(epochs, lr, model, train_loader, val_loader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [20], val_loss: 5571.0000\n",
            "Epoch [40], val_loss: 5571.0552\n",
            "Epoch [60], val_loss: 5571.0669\n",
            "Epoch [80], val_loss: 5570.9473\n",
            "Epoch [100], val_loss: 5570.9893\n",
            "Epoch [120], val_loss: 5571.0210\n",
            "Epoch [140], val_loss: 5570.9717\n",
            "Epoch [150], val_loss: 5570.9561\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sL2f39JsLWmi",
        "colab_type": "code",
        "outputId": "56024632-a671-4616-e6eb-5d09c8de8017",
        "colab": {}
      },
      "source": [
        "epochs = 200\n",
        "lr = 1e-5\n",
        "history4 = fit(epochs, lr, model, train_loader, val_loader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [20], val_loss: 5570.9351\n",
            "Epoch [40], val_loss: 5570.9297\n",
            "Epoch [60], val_loss: 5570.9370\n",
            "Epoch [80], val_loss: 5570.9360\n",
            "Epoch [100], val_loss: 5570.9360\n",
            "Epoch [120], val_loss: 5570.9360\n",
            "Epoch [140], val_loss: 5570.9380\n",
            "Epoch [160], val_loss: 5570.9375\n",
            "Epoch [180], val_loss: 5570.9414\n",
            "Epoch [200], val_loss: 5570.9429\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vr-pfrtFLWmn",
        "colab_type": "code",
        "outputId": "a870ceb8-310a-45dc-f8af-ce4c62580cda",
        "colab": {}
      },
      "source": [
        "epochs = 250\n",
        "lr = 1e-6\n",
        "history5 = fit(epochs, lr, model, train_loader, val_loader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [20], val_loss: 5570.9277\n",
            "Epoch [40], val_loss: 5570.9165\n",
            "Epoch [60], val_loss: 5570.9067\n",
            "Epoch [80], val_loss: 5570.8979\n",
            "Epoch [100], val_loss: 5570.8906\n",
            "Epoch [120], val_loss: 5570.8862\n",
            "Epoch [140], val_loss: 5570.8813\n",
            "Epoch [160], val_loss: 5570.8774\n",
            "Epoch [180], val_loss: 5570.8745\n",
            "Epoch [200], val_loss: 5570.8687\n",
            "Epoch [220], val_loss: 5570.8638\n",
            "Epoch [240], val_loss: 5570.8594\n",
            "Epoch [250], val_loss: 5570.8564\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVqA7ty4LWmq",
        "colab_type": "text"
      },
      "source": [
        "**Q: What is the final validation loss of your model?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VU7rtIXLWmq",
        "colab_type": "code",
        "outputId": "f2a5af0a-154f-4f2b-e89b-b5e1e17ef090",
        "colab": {}
      },
      "source": [
        "val_loss = [result] + history1 + history2 + history3 + history4 + history5\n",
        "print(val_loss)\n",
        "val_loss_list = [vl['val_loss'] for vl in val_loss]\n",
        "\n",
        "plt.plot(val_loss_list, '-x')\n",
        "\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('losses')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[{'val_loss': 12787.3271484375}, {'val_loss': 6847.42041015625}, {'val_loss': 6657.380859375}, {'val_loss': 6490.6953125}, {'val_loss': 6348.4541015625}, {'val_loss': 6264.07568359375}, {'val_loss': 6204.02978515625}, {'val_loss': 6171.87353515625}, {'val_loss': 6161.603515625}, {'val_loss': 6146.13427734375}, {'val_loss': 6149.8232421875}, {'val_loss': 6136.67626953125}, {'val_loss': 6144.05859375}, {'val_loss': 6130.57373046875}, {'val_loss': 6137.19482421875}, {'val_loss': 6127.52783203125}, {'val_loss': 6135.84814453125}, {'val_loss': 6125.6796875}, {'val_loss': 6124.251953125}, {'val_loss': 6123.0927734375}, {'val_loss': 6130.41162109375}, {'val_loss': 6122.95654296875}, {'val_loss': 6127.005859375}, {'val_loss': 6119.43359375}, {'val_loss': 6180.89453125}, {'val_loss': 6116.294921875}, {'val_loss': 6122.326171875}, {'val_loss': 6117.21240234375}, {'val_loss': 6113.53271484375}, {'val_loss': 6117.603515625}, {'val_loss': 6114.0263671875}, {'val_loss': 6110.16162109375}, {'val_loss': 6110.869140625}, {'val_loss': 6107.796875}, {'val_loss': 6107.9521484375}, {'val_loss': 6106.392578125}, {'val_loss': 6104.8271484375}, {'val_loss': 6104.66162109375}, {'val_loss': 6105.03271484375}, {'val_loss': 6105.56640625}, {'val_loss': 6107.72216796875}, {'val_loss': 6101.11376953125}, {'val_loss': 6100.96435546875}, {'val_loss': 6109.45263671875}, {'val_loss': 6099.02880859375}, {'val_loss': 6096.50439453125}, {'val_loss': 6097.5263671875}, {'val_loss': 6094.88427734375}, {'val_loss': 6096.75537109375}, {'val_loss': 6127.423828125}, {'val_loss': 6093.84814453125}, {'val_loss': 6091.6513671875}, {'val_loss': 6100.8291015625}, {'val_loss': 6091.08203125}, {'val_loss': 6091.84912109375}, {'val_loss': 6093.5625}, {'val_loss': 6090.55078125}, {'val_loss': 6091.27490234375}, {'val_loss': 6086.06787109375}, {'val_loss': 6085.15869140625}, {'val_loss': 6084.44921875}, {'val_loss': 6100.33349609375}, {'val_loss': 6086.564453125}, {'val_loss': 6082.802734375}, {'val_loss': 6081.580078125}, {'val_loss': 6096.1376953125}, {'val_loss': 6086.826171875}, {'val_loss': 6101.705078125}, {'val_loss': 6080.7080078125}, {'val_loss': 6077.86181640625}, {'val_loss': 6081.81689453125}, {'val_loss': 6076.6708984375}, {'val_loss': 6075.998046875}, {'val_loss': 6080.50439453125}, {'val_loss': 6088.6513671875}, {'val_loss': 6081.115234375}, {'val_loss': 6073.5498046875}, {'val_loss': 6072.98828125}, {'val_loss': 6072.2763671875}, {'val_loss': 6077.76904296875}, {'val_loss': 6071.4033203125}, {'val_loss': 6076.84326171875}, {'val_loss': 6072.35595703125}, {'val_loss': 6071.0810546875}, {'val_loss': 6070.16845703125}, {'val_loss': 6071.58349609375}, {'val_loss': 6077.32568359375}, {'val_loss': 6067.53466796875}, {'val_loss': 6070.6044921875}, {'val_loss': 6067.96630859375}, {'val_loss': 6088.78955078125}, {'val_loss': 6068.45654296875}, {'val_loss': 6067.2314453125}, {'val_loss': 6071.45703125}, {'val_loss': 6068.06982421875}, {'val_loss': 6062.50048828125}, {'val_loss': 6063.7421875}, {'val_loss': 6064.259765625}, {'val_loss': 6062.4111328125}, {'val_loss': 6065.580078125}, {'val_loss': 6062.56103515625}, {'val_loss': 6059.09814453125}, {'val_loss': 6060.40087890625}, {'val_loss': 6061.556640625}, {'val_loss': 6057.5205078125}, {'val_loss': 6072.45849609375}, {'val_loss': 6056.18212890625}, {'val_loss': 6062.02978515625}, {'val_loss': 6055.05859375}, {'val_loss': 6054.7841796875}, {'val_loss': 6053.9521484375}, {'val_loss': 6057.82958984375}, {'val_loss': 6053.0830078125}, {'val_loss': 6055.05712890625}, {'val_loss': 6053.40869140625}, {'val_loss': 6060.80859375}, {'val_loss': 6056.2724609375}, {'val_loss': 6050.62841796875}, {'val_loss': 6052.28466796875}, {'val_loss': 6052.865234375}, {'val_loss': 6054.72705078125}, {'val_loss': 6067.62158203125}, {'val_loss': 6047.2099609375}, {'val_loss': 6048.80615234375}, {'val_loss': 6054.95458984375}, {'val_loss': 6046.03173828125}, {'val_loss': 6050.41357421875}, {'val_loss': 6046.5078125}, {'val_loss': 6044.40673828125}, {'val_loss': 6050.501953125}, {'val_loss': 6044.3486328125}, {'val_loss': 6043.83544921875}, {'val_loss': 6049.65869140625}, {'val_loss': 6045.763671875}, {'val_loss': 6042.185546875}, {'val_loss': 6042.4462890625}, {'val_loss': 6043.86865234375}, {'val_loss': 6047.98046875}, {'val_loss': 6038.751953125}, {'val_loss': 6039.23291015625}, {'val_loss': 6039.00732421875}, {'val_loss': 6038.18212890625}, {'val_loss': 6051.18896484375}, {'val_loss': 6062.638671875}, {'val_loss': 6036.25732421875}, {'val_loss': 6035.68994140625}, {'val_loss': 6040.61865234375}, {'val_loss': 6049.19091796875}, {'val_loss': 6040.32373046875}, {'val_loss': 6032.7412109375}, {'val_loss': 6036.03662109375}, {'val_loss': 6034.44091796875}, {'val_loss': 6034.365234375}, {'val_loss': 6040.26513671875}, {'val_loss': 6031.689453125}, {'val_loss': 6037.25439453125}, {'val_loss': 6041.0185546875}, {'val_loss': 6034.72412109375}, {'val_loss': 6028.83349609375}, {'val_loss': 6028.93798828125}, {'val_loss': 6037.6044921875}, {'val_loss': 6027.72216796875}, {'val_loss': 6034.0947265625}, {'val_loss': 6037.328125}, {'val_loss': 6026.083984375}, {'val_loss': 6025.31005859375}, {'val_loss': 6024.6962890625}, {'val_loss': 6028.3994140625}, {'val_loss': 6023.5986328125}, {'val_loss': 6028.65869140625}, {'val_loss': 6025.74072265625}, {'val_loss': 6022.1474609375}, {'val_loss': 6022.2080078125}, {'val_loss': 6022.28662109375}, {'val_loss': 6036.44482421875}, {'val_loss': 6021.66259765625}, {'val_loss': 6081.63134765625}, {'val_loss': 6020.728515625}, {'val_loss': 6028.33935546875}, {'val_loss': 6030.18115234375}, {'val_loss': 6019.74853515625}, {'val_loss': 6018.9228515625}, {'val_loss': 6035.41064453125}, {'val_loss': 6024.6953125}, {'val_loss': 6020.97607421875}, {'val_loss': 6019.52783203125}, {'val_loss': 6018.4814453125}, {'val_loss': 6019.6162109375}, {'val_loss': 6015.70849609375}, {'val_loss': 6017.2763671875}, {'val_loss': 6014.48095703125}, {'val_loss': 6022.04541015625}, {'val_loss': 6031.0732421875}, {'val_loss': 6015.4150390625}, {'val_loss': 6014.43115234375}, {'val_loss': 6029.05517578125}, {'val_loss': 6030.81103515625}, {'val_loss': 6010.4150390625}, {'val_loss': 6011.7626953125}, {'val_loss': 6013.30712890625}, {'val_loss': 6009.28076171875}, {'val_loss': 6018.27294921875}, {'val_loss': 6008.9013671875}, {'val_loss': 6009.4873046875}, {'val_loss': 6016.083984375}, {'val_loss': 6009.7333984375}, {'val_loss': 6005.79736328125}, {'val_loss': 6018.96728515625}, {'val_loss': 6007.267578125}, {'val_loss': 6014.77392578125}, {'val_loss': 6005.39990234375}, {'val_loss': 6004.20263671875}, {'val_loss': 6009.2822265625}, {'val_loss': 6005.52783203125}, {'val_loss': 6005.1416015625}, {'val_loss': 6005.173828125}, {'val_loss': 6002.22412109375}, {'val_loss': 6005.09326171875}, {'val_loss': 6004.62646484375}, {'val_loss': 6001.19482421875}, {'val_loss': 6016.01171875}, {'val_loss': 5998.5322265625}, {'val_loss': 6020.72314453125}, {'val_loss': 6000.267578125}, {'val_loss': 6008.7998046875}, {'val_loss': 6000.96435546875}, {'val_loss': 6005.5625}, {'val_loss': 5999.078125}, {'val_loss': 5995.57373046875}, {'val_loss': 5995.32177734375}, {'val_loss': 5996.18212890625}, {'val_loss': 6001.9794921875}, {'val_loss': 5995.18212890625}, {'val_loss': 6002.1796875}, {'val_loss': 5993.1875}, {'val_loss': 5995.296875}, {'val_loss': 5994.357421875}, {'val_loss': 5991.4013671875}, {'val_loss': 6005.87744140625}, {'val_loss': 5990.47607421875}, {'val_loss': 5995.31201171875}, {'val_loss': 5998.828125}, {'val_loss': 5996.74755859375}, {'val_loss': 6007.80517578125}, {'val_loss': 5987.876953125}, {'val_loss': 5999.1376953125}, {'val_loss': 5987.48291015625}, {'val_loss': 5987.82373046875}, {'val_loss': 5991.93896484375}, {'val_loss': 5986.20263671875}, {'val_loss': 6010.294921875}, {'val_loss': 5984.84130859375}, {'val_loss': 5991.03173828125}, {'val_loss': 5984.0}, {'val_loss': 5991.85791015625}, {'val_loss': 5991.38134765625}, {'val_loss': 5985.22021484375}, {'val_loss': 5991.17578125}, {'val_loss': 5982.236328125}, {'val_loss': 5995.0791015625}, {'val_loss': 5995.31591796875}, {'val_loss': 5980.18359375}, {'val_loss': 5979.0947265625}, {'val_loss': 5979.24267578125}, {'val_loss': 5978.451171875}, {'val_loss': 5982.29345703125}, {'val_loss': 5985.35546875}, {'val_loss': 5981.49658203125}, {'val_loss': 5978.1376953125}, {'val_loss': 5986.7333984375}, {'val_loss': 5985.71826171875}, {'val_loss': 5996.74609375}, {'val_loss': 5974.884765625}, {'val_loss': 5980.8232421875}, {'val_loss': 5980.0498046875}, {'val_loss': 5973.068359375}, {'val_loss': 5973.01513671875}, {'val_loss': 5980.71630859375}, {'val_loss': 5980.92578125}, {'val_loss': 5971.2744140625}, {'val_loss': 5972.4033203125}, {'val_loss': 5971.31640625}, {'val_loss': 5980.12548828125}, {'val_loss': 5974.0751953125}, {'val_loss': 5969.7626953125}, {'val_loss': 5973.61376953125}, {'val_loss': 5971.36572265625}, {'val_loss': 5974.3935546875}, {'val_loss': 5971.90478515625}, {'val_loss': 5971.3916015625}, {'val_loss': 5968.43017578125}, {'val_loss': 5969.32421875}, {'val_loss': 5969.8251953125}, {'val_loss': 5970.59716796875}, {'val_loss': 5974.28955078125}, {'val_loss': 5965.50341796875}, {'val_loss': 5970.5986328125}, {'val_loss': 5966.82958984375}, {'val_loss': 5967.25341796875}, {'val_loss': 5982.65869140625}, {'val_loss': 5970.69287109375}, {'val_loss': 5960.3525390625}, {'val_loss': 5966.13037109375}, {'val_loss': 5959.73095703125}, {'val_loss': 5961.9453125}, {'val_loss': 5967.93408203125}, {'val_loss': 5971.31982421875}, {'val_loss': 5961.04931640625}, {'val_loss': 5963.27880859375}, {'val_loss': 5961.955078125}, {'val_loss': 5956.4052734375}, {'val_loss': 5959.013671875}, {'val_loss': 5955.70849609375}, {'val_loss': 5957.5458984375}, {'val_loss': 5958.2607421875}, {'val_loss': 5956.13818359375}, {'val_loss': 5953.2724609375}, {'val_loss': 5962.73046875}, {'val_loss': 5958.59521484375}, {'val_loss': 5964.90087890625}, {'val_loss': 5951.71630859375}, {'val_loss': 5951.484375}, {'val_loss': 5952.43408203125}, {'val_loss': 5950.40380859375}, {'val_loss': 5951.80078125}, {'val_loss': 5951.31689453125}, {'val_loss': 5953.947265625}, {'val_loss': 5965.001953125}, {'val_loss': 5947.259765625}, {'val_loss': 5969.91796875}, {'val_loss': 5979.51513671875}, {'val_loss': 5945.88671875}, {'val_loss': 5948.7939453125}, {'val_loss': 5944.83349609375}, {'val_loss': 5945.513671875}, {'val_loss': 5948.4375}, {'val_loss': 5943.49609375}, {'val_loss': 5944.29541015625}, {'val_loss': 5949.04931640625}, {'val_loss': 5944.02685546875}, {'val_loss': 5942.001953125}, {'val_loss': 5953.84130859375}, {'val_loss': 5940.5400390625}, {'val_loss': 5945.431640625}, {'val_loss': 5958.72900390625}, {'val_loss': 5939.07177734375}, {'val_loss': 5963.2783203125}, {'val_loss': 5947.431640625}, {'val_loss': 5937.76904296875}, {'val_loss': 5937.876953125}, {'val_loss': 5940.0712890625}, {'val_loss': 5936.380859375}, {'val_loss': 5955.33642578125}, {'val_loss': 5936.53369140625}, {'val_loss': 5937.68359375}, {'val_loss': 5962.75634765625}, {'val_loss': 5966.63623046875}, {'val_loss': 5941.31884765625}, {'val_loss': 5932.72119140625}, {'val_loss': 5940.16259765625}, {'val_loss': 5940.13818359375}, {'val_loss': 5933.1474609375}, {'val_loss': 5935.43994140625}, {'val_loss': 5931.06982421875}, {'val_loss': 5936.49853515625}, {'val_loss': 5929.4033203125}, {'val_loss': 5931.4775390625}, {'val_loss': 5941.3505859375}, {'val_loss': 5928.39208984375}, {'val_loss': 5927.90087890625}, {'val_loss': 5936.359375}, {'val_loss': 5934.2744140625}, {'val_loss': 5926.501953125}, {'val_loss': 5931.22216796875}, {'val_loss': 5925.365234375}, {'val_loss': 5924.7861328125}, {'val_loss': 5929.9921875}, {'val_loss': 5924.06689453125}, {'val_loss': 5923.0302734375}, {'val_loss': 5924.4072265625}, {'val_loss': 5923.36767578125}, {'val_loss': 5928.90869140625}, {'val_loss': 5920.99072265625}, {'val_loss': 5942.271484375}, {'val_loss': 5923.91357421875}, {'val_loss': 5921.90771484375}, {'val_loss': 5919.1103515625}, {'val_loss': 5921.08837890625}, {'val_loss': 5920.03466796875}, {'val_loss': 5918.271484375}, {'val_loss': 5917.43994140625}, {'val_loss': 5916.81005859375}, {'val_loss': 5919.64599609375}, {'val_loss': 5919.318359375}, {'val_loss': 5915.76953125}, {'val_loss': 5915.18505859375}, {'val_loss': 5913.91796875}, {'val_loss': 5913.83837890625}, {'val_loss': 5913.07177734375}, {'val_loss': 5925.2939453125}, {'val_loss': 5912.5380859375}, {'val_loss': 5911.40380859375}, {'val_loss': 5927.2236328125}, {'val_loss': 5911.14794921875}, {'val_loss': 5910.12451171875}, {'val_loss': 5909.72216796875}, {'val_loss': 5910.53857421875}, {'val_loss': 5908.947265625}, {'val_loss': 5909.6591796875}, {'val_loss': 5913.1494140625}, {'val_loss': 5919.8896484375}, {'val_loss': 5908.11865234375}, {'val_loss': 5906.146484375}, {'val_loss': 5906.265625}, {'val_loss': 5905.4375}, {'val_loss': 5905.0087890625}, {'val_loss': 5904.171875}, {'val_loss': 5903.8564453125}, {'val_loss': 5915.61376953125}, {'val_loss': 5905.14794921875}, {'val_loss': 5912.3037109375}, {'val_loss': 5906.4169921875}, {'val_loss': 5930.375}, {'val_loss': 5901.791015625}, {'val_loss': 5911.318359375}, {'val_loss': 5900.52490234375}, {'val_loss': 5900.2607421875}, {'val_loss': 5898.99853515625}, {'val_loss': 5905.50048828125}, {'val_loss': 5920.91455078125}, {'val_loss': 5898.13671875}, {'val_loss': 5901.5546875}, {'val_loss': 5897.85205078125}, {'val_loss': 5896.072265625}, {'val_loss': 5904.71435546875}, {'val_loss': 5896.17578125}, {'val_loss': 5894.76708984375}, {'val_loss': 5896.0791015625}, {'val_loss': 5895.326171875}, {'val_loss': 5941.31103515625}, {'val_loss': 5900.29931640625}, {'val_loss': 5892.802734375}, {'val_loss': 5892.10546875}, {'val_loss': 5891.732421875}, {'val_loss': 5890.810546875}, {'val_loss': 5891.71337890625}, {'val_loss': 5890.28564453125}, {'val_loss': 5893.2763671875}, {'val_loss': 5893.2919921875}, {'val_loss': 5892.166015625}, {'val_loss': 5898.44873046875}, {'val_loss': 5888.3017578125}, {'val_loss': 5906.548828125}, {'val_loss': 5888.6611328125}, {'val_loss': 5891.201171875}, {'val_loss': 5885.71826171875}, {'val_loss': 5885.84033203125}, {'val_loss': 5884.1728515625}, {'val_loss': 5883.92041015625}, {'val_loss': 5916.79296875}, {'val_loss': 5890.65966796875}, {'val_loss': 5882.40673828125}, {'val_loss': 5898.4541015625}, {'val_loss': 5889.28759765625}, {'val_loss': 5881.59716796875}, {'val_loss': 5880.0185546875}, {'val_loss': 5880.541015625}, {'val_loss': 5886.8369140625}, {'val_loss': 5880.50537109375}, {'val_loss': 5879.27294921875}, {'val_loss': 5877.6533203125}, {'val_loss': 5887.01123046875}, {'val_loss': 5877.76513671875}, {'val_loss': 5876.068359375}, {'val_loss': 5879.17578125}, {'val_loss': 5881.814453125}, {'val_loss': 5874.40673828125}, {'val_loss': 5874.59814453125}, {'val_loss': 5877.546875}, {'val_loss': 5873.5947265625}, {'val_loss': 5885.90283203125}, {'val_loss': 5872.994140625}, {'val_loss': 5873.99609375}, {'val_loss': 5871.53271484375}, {'val_loss': 5871.12939453125}, {'val_loss': 5881.00146484375}, {'val_loss': 5876.1875}, {'val_loss': 5871.71044921875}, {'val_loss': 5873.0517578125}, {'val_loss': 5868.08154296875}, {'val_loss': 5868.69091796875}, {'val_loss': 5867.818359375}, {'val_loss': 5866.68310546875}, {'val_loss': 5865.99658203125}, {'val_loss': 5869.990234375}, {'val_loss': 5865.50341796875}, {'val_loss': 5865.78857421875}, {'val_loss': 5871.2998046875}, {'val_loss': 5875.30517578125}, {'val_loss': 5868.4892578125}, {'val_loss': 5873.7607421875}, {'val_loss': 5861.78466796875}, {'val_loss': 5869.60595703125}, {'val_loss': 5861.0400390625}, {'val_loss': 5869.81689453125}, {'val_loss': 5860.15185546875}, {'val_loss': 5868.9189453125}, {'val_loss': 5859.7138671875}, {'val_loss': 5860.68798828125}, {'val_loss': 5861.93017578125}, {'val_loss': 5891.138671875}, {'val_loss': 5858.326171875}, {'val_loss': 5858.234375}, {'val_loss': 5862.5546875}, {'val_loss': 5862.05078125}, {'val_loss': 5856.81201171875}, {'val_loss': 5859.95849609375}, {'val_loss': 5854.8583984375}, {'val_loss': 5853.98486328125}, {'val_loss': 5854.6328125}, {'val_loss': 5852.96826171875}, {'val_loss': 5852.77587890625}, {'val_loss': 5853.4482421875}, {'val_loss': 5851.47705078125}, {'val_loss': 5851.7060546875}, {'val_loss': 5857.03466796875}, {'val_loss': 5849.91357421875}, {'val_loss': 5850.54345703125}, {'val_loss': 5849.74658203125}, {'val_loss': 5849.927734375}, {'val_loss': 5852.85595703125}, {'val_loss': 5847.916015625}, {'val_loss': 5848.23046875}, {'val_loss': 5848.05712890625}, {'val_loss': 5847.65380859375}, {'val_loss': 5845.88818359375}, {'val_loss': 5845.521484375}, {'val_loss': 5844.8251953125}, {'val_loss': 5843.72216796875}, {'val_loss': 5856.5869140625}, {'val_loss': 5843.3671875}, {'val_loss': 5842.72216796875}, {'val_loss': 5842.009765625}, {'val_loss': 5861.4794921875}, {'val_loss': 5840.736328125}, {'val_loss': 5840.30517578125}, {'val_loss': 5844.20849609375}, {'val_loss': 5842.080078125}, {'val_loss': 5838.7841796875}, {'val_loss': 5838.60986328125}, {'val_loss': 5874.56884765625}, {'val_loss': 5838.5478515625}, {'val_loss': 5837.37841796875}, {'val_loss': 5838.26318359375}, {'val_loss': 5836.79296875}, {'val_loss': 5854.6962890625}, {'val_loss': 5835.00927734375}, {'val_loss': 5835.86962890625}, {'val_loss': 5835.3603515625}, {'val_loss': 5833.6708984375}, {'val_loss': 5833.09228515625}, {'val_loss': 5848.42626953125}, {'val_loss': 5832.328125}, {'val_loss': 5832.24951171875}, {'val_loss': 5840.333984375}, {'val_loss': 5859.236328125}, {'val_loss': 5830.05908203125}, {'val_loss': 5844.38427734375}, {'val_loss': 5862.1142578125}, {'val_loss': 5829.1962890625}, {'val_loss': 5827.79150390625}, {'val_loss': 5828.87109375}, {'val_loss': 5840.8212890625}, {'val_loss': 5835.09912109375}, {'val_loss': 5830.1708984375}, {'val_loss': 5825.9453125}, {'val_loss': 5827.291015625}, {'val_loss': 5826.76953125}, {'val_loss': 5826.2041015625}, {'val_loss': 5823.63037109375}, {'val_loss': 5822.98046875}, {'val_loss': 5823.259765625}, {'val_loss': 5822.421875}, {'val_loss': 5859.16455078125}, {'val_loss': 5827.041015625}, {'val_loss': 5827.732421875}, {'val_loss': 5821.65185546875}, {'val_loss': 5819.6689453125}, {'val_loss': 5819.15771484375}, {'val_loss': 5819.00439453125}, {'val_loss': 5819.72412109375}, {'val_loss': 5818.884765625}, {'val_loss': 5817.95263671875}, {'val_loss': 5817.7646484375}, {'val_loss': 5817.53564453125}, {'val_loss': 5818.32373046875}, {'val_loss': 5816.86767578125}, {'val_loss': 5818.076171875}, {'val_loss': 5817.9755859375}, {'val_loss': 5813.56201171875}, {'val_loss': 5815.015625}, {'val_loss': 5813.30810546875}, {'val_loss': 5811.79736328125}, {'val_loss': 5813.91064453125}, {'val_loss': 5815.42578125}, {'val_loss': 5827.9775390625}, {'val_loss': 5810.78369140625}, {'val_loss': 5809.3837890625}, {'val_loss': 5844.251953125}, {'val_loss': 5810.06982421875}, {'val_loss': 5808.822265625}, {'val_loss': 5816.01171875}, {'val_loss': 5809.689453125}, {'val_loss': 5806.39892578125}, {'val_loss': 5821.17431640625}, {'val_loss': 5805.94677734375}, {'val_loss': 5807.11865234375}, {'val_loss': 5804.63623046875}, {'val_loss': 5804.73876953125}, {'val_loss': 5804.43798828125}, {'val_loss': 5806.24267578125}, {'val_loss': 5802.56494140625}, {'val_loss': 5803.2392578125}, {'val_loss': 5801.31640625}, {'val_loss': 5802.8857421875}, {'val_loss': 5800.47900390625}, {'val_loss': 5801.09716796875}, {'val_loss': 5800.1142578125}, {'val_loss': 5804.45068359375}, {'val_loss': 5799.9921875}, {'val_loss': 5798.3017578125}, {'val_loss': 5797.447265625}, {'val_loss': 5797.4697265625}, {'val_loss': 5798.251953125}, {'val_loss': 5796.67431640625}, {'val_loss': 5802.17431640625}, {'val_loss': 5814.93994140625}, {'val_loss': 5797.1044921875}, {'val_loss': 5794.294921875}, {'val_loss': 5800.97119140625}, {'val_loss': 5793.744140625}, {'val_loss': 5792.95068359375}, {'val_loss': 5792.39599609375}, {'val_loss': 5792.06640625}, {'val_loss': 5797.4013671875}, {'val_loss': 5809.56396484375}, {'val_loss': 5794.98828125}, {'val_loss': 5798.35107421875}, {'val_loss': 5789.68701171875}, {'val_loss': 5788.7041015625}, {'val_loss': 5788.423828125}, {'val_loss': 5788.2392578125}, {'val_loss': 5787.56689453125}, {'val_loss': 5788.748046875}, {'val_loss': 5786.0888671875}, {'val_loss': 5786.005859375}, {'val_loss': 5785.9892578125}, {'val_loss': 5784.953125}, {'val_loss': 5784.1669921875}, {'val_loss': 5798.74462890625}, {'val_loss': 5785.05810546875}, {'val_loss': 5804.22021484375}, {'val_loss': 5784.4228515625}, {'val_loss': 5788.2255859375}, {'val_loss': 5793.890625}, {'val_loss': 5781.07421875}, {'val_loss': 5782.7421875}, {'val_loss': 5779.98486328125}, {'val_loss': 5815.419921875}, {'val_loss': 5783.3486328125}, {'val_loss': 5782.43017578125}, {'val_loss': 5777.876953125}, {'val_loss': 5777.0703125}, {'val_loss': 5778.5712890625}, {'val_loss': 5778.46923828125}, {'val_loss': 5775.69287109375}, {'val_loss': 5775.41064453125}, {'val_loss': 5779.48486328125}, {'val_loss': 5774.6083984375}, {'val_loss': 5782.09033203125}, {'val_loss': 5773.59814453125}, {'val_loss': 5773.44921875}, {'val_loss': 5772.59130859375}, {'val_loss': 5772.18310546875}, {'val_loss': 5772.578125}, {'val_loss': 5773.3505859375}, {'val_loss': 5772.634765625}, {'val_loss': 5770.0791015625}, {'val_loss': 5769.67431640625}, {'val_loss': 5769.576171875}, {'val_loss': 5778.205078125}, {'val_loss': 5768.28369140625}, {'val_loss': 5770.55517578125}, {'val_loss': 5772.93408203125}, {'val_loss': 5769.33544921875}, {'val_loss': 5770.92236328125}, {'val_loss': 5765.43603515625}, {'val_loss': 5765.2216796875}, {'val_loss': 5767.90478515625}, {'val_loss': 5766.236328125}, {'val_loss': 5766.59423828125}, {'val_loss': 5763.38037109375}, {'val_loss': 5768.16796875}, {'val_loss': 5766.8837890625}, {'val_loss': 5766.7958984375}, {'val_loss': 5761.83349609375}, {'val_loss': 5773.07177734375}, {'val_loss': 5760.81396484375}, {'val_loss': 5774.173828125}, {'val_loss': 5759.416015625}, {'val_loss': 5761.2255859375}, {'val_loss': 5760.06298828125}, {'val_loss': 5757.5771484375}, {'val_loss': 5757.57421875}, {'val_loss': 5790.2900390625}, {'val_loss': 5756.35009765625}, {'val_loss': 5755.642578125}, {'val_loss': 5755.3896484375}, {'val_loss': 5754.76171875}, {'val_loss': 5755.3935546875}, {'val_loss': 5754.1083984375}, {'val_loss': 5755.169921875}, {'val_loss': 5759.5107421875}, {'val_loss': 5755.0986328125}, {'val_loss': 5751.57763671875}, {'val_loss': 5766.90283203125}, {'val_loss': 5750.7373046875}, {'val_loss': 5750.740234375}, {'val_loss': 5751.97412109375}, {'val_loss': 5752.4892578125}, {'val_loss': 5750.92236328125}, {'val_loss': 5748.52685546875}, {'val_loss': 5747.7646484375}, {'val_loss': 5748.796875}, {'val_loss': 5746.97314453125}, {'val_loss': 5751.02490234375}, {'val_loss': 5747.06494140625}, {'val_loss': 5745.81298828125}, {'val_loss': 5744.81298828125}, {'val_loss': 5747.5126953125}, {'val_loss': 5744.373046875}, {'val_loss': 5743.6123046875}, {'val_loss': 5754.421875}, {'val_loss': 5742.49365234375}, {'val_loss': 5757.96337890625}, {'val_loss': 5747.18701171875}, {'val_loss': 5743.5712890625}, {'val_loss': 5740.4072265625}, {'val_loss': 5741.7177734375}, {'val_loss': 5739.26904296875}, {'val_loss': 5746.736328125}, {'val_loss': 5740.79931640625}, {'val_loss': 5757.1953125}, {'val_loss': 5739.896484375}, {'val_loss': 5760.34033203125}, {'val_loss': 5749.29296875}, {'val_loss': 5739.66064453125}, {'val_loss': 5735.6611328125}, {'val_loss': 5736.00390625}, {'val_loss': 5742.6533203125}, {'val_loss': 5734.10595703125}, {'val_loss': 5733.927734375}, {'val_loss': 5733.06787109375}, {'val_loss': 5747.16455078125}, {'val_loss': 5732.29931640625}, {'val_loss': 5740.42822265625}, {'val_loss': 5731.6328125}, {'val_loss': 5731.91064453125}, {'val_loss': 5732.3046875}, {'val_loss': 5734.978515625}, {'val_loss': 5729.38818359375}, {'val_loss': 5744.28076171875}, {'val_loss': 5730.74658203125}, {'val_loss': 5727.77587890625}, {'val_loss': 5733.68994140625}, {'val_loss': 5726.87939453125}, {'val_loss': 5727.85009765625}, {'val_loss': 5726.2060546875}, {'val_loss': 5727.4755859375}, {'val_loss': 5724.9521484375}, {'val_loss': 5739.4619140625}, {'val_loss': 5740.39599609375}, {'val_loss': 5728.94189453125}, {'val_loss': 5725.21142578125}, {'val_loss': 5722.5322265625}, {'val_loss': 5722.693359375}, {'val_loss': 5732.97705078125}, {'val_loss': 5721.181640625}, {'val_loss': 5751.03271484375}, {'val_loss': 5724.83203125}, {'val_loss': 5724.0439453125}, {'val_loss': 5724.65283203125}, {'val_loss': 5723.2587890625}, {'val_loss': 5717.978515625}, {'val_loss': 5717.51904296875}, {'val_loss': 5717.08203125}, {'val_loss': 5716.40478515625}, {'val_loss': 5716.884765625}, {'val_loss': 5716.35400390625}, {'val_loss': 5715.244140625}, {'val_loss': 5714.9697265625}, {'val_loss': 5734.01953125}, {'val_loss': 5713.6123046875}, {'val_loss': 5718.39794921875}, {'val_loss': 5712.75244140625}, {'val_loss': 5713.06396484375}, {'val_loss': 5712.02294921875}, {'val_loss': 5727.0712890625}, {'val_loss': 5713.1376953125}, {'val_loss': 5710.00244140625}, {'val_loss': 5716.4716796875}, {'val_loss': 5710.06396484375}, {'val_loss': 5708.4501953125}, {'val_loss': 5710.88037109375}, {'val_loss': 5715.15966796875}, {'val_loss': 5708.1748046875}, {'val_loss': 5706.69921875}, {'val_loss': 5706.49072265625}, {'val_loss': 5707.9853515625}, {'val_loss': 5720.3447265625}, {'val_loss': 5706.126953125}, {'val_loss': 5704.29345703125}, {'val_loss': 5706.15673828125}, {'val_loss': 5705.84326171875}, {'val_loss': 5705.3125}, {'val_loss': 5702.06103515625}, {'val_loss': 5708.0078125}, {'val_loss': 5701.34619140625}, {'val_loss': 5700.7041015625}, {'val_loss': 5707.927734375}, {'val_loss': 5705.89599609375}, {'val_loss': 5699.4814453125}, {'val_loss': 5698.80859375}, {'val_loss': 5698.3837890625}, {'val_loss': 5698.9541015625}, {'val_loss': 5698.72021484375}, {'val_loss': 5698.93212890625}, {'val_loss': 5698.06201171875}, {'val_loss': 5714.572265625}, {'val_loss': 5695.49267578125}, {'val_loss': 5697.46044921875}, {'val_loss': 5706.87158203125}, {'val_loss': 5703.86376953125}, {'val_loss': 5705.06640625}, {'val_loss': 5694.2646484375}, {'val_loss': 5694.0244140625}, {'val_loss': 5697.06201171875}, {'val_loss': 5694.53759765625}, {'val_loss': 5695.69140625}, {'val_loss': 5695.84814453125}, {'val_loss': 5690.14013671875}, {'val_loss': 5695.6416015625}, {'val_loss': 5689.04931640625}, {'val_loss': 5699.2802734375}, {'val_loss': 5691.02099609375}, {'val_loss': 5690.15087890625}, {'val_loss': 5688.60986328125}, {'val_loss': 5690.62939453125}, {'val_loss': 5686.12109375}, {'val_loss': 5687.21044921875}, {'val_loss': 5684.98876953125}, {'val_loss': 5700.0498046875}, {'val_loss': 5687.7626953125}, {'val_loss': 5688.234375}, {'val_loss': 5683.3505859375}, {'val_loss': 5683.6064453125}, {'val_loss': 5682.5751953125}, {'val_loss': 5681.72705078125}, {'val_loss': 5682.1455078125}, {'val_loss': 5688.01171875}, {'val_loss': 5725.9267578125}, {'val_loss': 5694.482421875}, {'val_loss': 5686.6025390625}, {'val_loss': 5679.1513671875}, {'val_loss': 5681.9716796875}, {'val_loss': 5680.578125}, {'val_loss': 5678.81005859375}, {'val_loss': 5705.2158203125}, {'val_loss': 5679.1455078125}, {'val_loss': 5676.34033203125}, {'val_loss': 5675.57763671875}, {'val_loss': 5698.24560546875}, {'val_loss': 5674.82177734375}, {'val_loss': 5679.6123046875}, {'val_loss': 5674.2861328125}, {'val_loss': 5672.9013671875}, {'val_loss': 5680.70068359375}, {'val_loss': 5698.3994140625}, {'val_loss': 5673.8203125}, {'val_loss': 5675.5849609375}, {'val_loss': 5684.189453125}, {'val_loss': 5670.93212890625}, {'val_loss': 5672.91064453125}, {'val_loss': 5671.4267578125}, {'val_loss': 5670.2255859375}, {'val_loss': 5672.3564453125}, {'val_loss': 5668.1123046875}, {'val_loss': 5676.359375}, {'val_loss': 5666.6630859375}, {'val_loss': 5666.68701171875}, {'val_loss': 5687.15283203125}, {'val_loss': 5670.58740234375}, {'val_loss': 5684.0439453125}, {'val_loss': 5670.83837890625}, {'val_loss': 5668.2587890625}, {'val_loss': 5664.15380859375}, {'val_loss': 5662.78662109375}, {'val_loss': 5665.20703125}, {'val_loss': 5664.427734375}, {'val_loss': 5661.4169921875}, {'val_loss': 5660.58544921875}, {'val_loss': 5665.556640625}, {'val_loss': 5667.67041015625}, {'val_loss': 5659.94677734375}, {'val_loss': 5658.953125}, {'val_loss': 5658.32177734375}, {'val_loss': 5659.37353515625}, {'val_loss': 5660.28076171875}, {'val_loss': 5688.833984375}, {'val_loss': 5661.7236328125}, {'val_loss': 5658.22216796875}, {'val_loss': 5666.91455078125}, {'val_loss': 5655.0107421875}, {'val_loss': 5681.9677734375}, {'val_loss': 5655.1337890625}, {'val_loss': 5655.6875}, {'val_loss': 5655.13623046875}, {'val_loss': 5657.44287109375}, {'val_loss': 5661.3203125}, {'val_loss': 5660.11181640625}, {'val_loss': 5658.103515625}, {'val_loss': 5650.86572265625}, {'val_loss': 5678.8251953125}, {'val_loss': 5649.9912109375}, {'val_loss': 5651.10595703125}, {'val_loss': 5649.47119140625}, {'val_loss': 5651.37744140625}, {'val_loss': 5652.43994140625}, {'val_loss': 5673.986328125}, {'val_loss': 5647.32373046875}, {'val_loss': 5646.23876953125}, {'val_loss': 5645.755859375}, {'val_loss': 5648.59716796875}, {'val_loss': 5658.22705078125}, {'val_loss': 5678.69189453125}, {'val_loss': 5648.5322265625}, {'val_loss': 5645.576171875}, {'val_loss': 5643.00341796875}, {'val_loss': 5644.65869140625}, {'val_loss': 5647.3974609375}, {'val_loss': 5641.935546875}, {'val_loss': 5644.79736328125}, {'val_loss': 5642.41796875}, {'val_loss': 5640.25048828125}, {'val_loss': 5644.5263671875}, {'val_loss': 5639.13134765625}, {'val_loss': 5642.84228515625}, {'val_loss': 5640.017578125}, {'val_loss': 5638.48046875}, {'val_loss': 5649.80908203125}, {'val_loss': 5640.65966796875}, {'val_loss': 5639.08544921875}, {'val_loss': 5667.65087890625}, {'val_loss': 5643.74072265625}, {'val_loss': 5646.0078125}, {'val_loss': 5635.42236328125}, {'val_loss': 5634.1044921875}, {'val_loss': 5639.05126953125}, {'val_loss': 5632.630859375}, {'val_loss': 5632.47021484375}, {'val_loss': 5633.0302734375}, {'val_loss': 5644.82421875}, {'val_loss': 5634.71435546875}, {'val_loss': 5633.4521484375}, {'val_loss': 5630.29150390625}, {'val_loss': 5635.798828125}, {'val_loss': 5632.04296875}, {'val_loss': 5628.39794921875}, {'val_loss': 5636.392578125}, {'val_loss': 5627.69921875}, {'val_loss': 5631.4111328125}, {'val_loss': 5627.44287109375}, {'val_loss': 5637.19482421875}, {'val_loss': 5628.25244140625}, {'val_loss': 5627.732421875}, {'val_loss': 5630.1513671875}, {'val_loss': 5625.35107421875}, {'val_loss': 5627.52294921875}, {'val_loss': 5624.61376953125}, {'val_loss': 5627.953125}, {'val_loss': 5621.90478515625}, {'val_loss': 5623.90478515625}, {'val_loss': 5622.9921875}, {'val_loss': 5631.115234375}, {'val_loss': 5636.85009765625}, {'val_loss': 5628.6591796875}, {'val_loss': 5619.7041015625}, {'val_loss': 5619.140625}, {'val_loss': 5618.3662109375}, {'val_loss': 5618.16064453125}, {'val_loss': 5622.55859375}, {'val_loss': 5617.21337890625}, {'val_loss': 5618.18603515625}, {'val_loss': 5617.43212890625}, {'val_loss': 5617.49853515625}, {'val_loss': 5617.111328125}, {'val_loss': 5616.93798828125}, {'val_loss': 5617.05859375}, {'val_loss': 5618.35595703125}, {'val_loss': 5617.40283203125}, {'val_loss': 5616.80078125}, {'val_loss': 5618.353515625}, {'val_loss': 5618.05126953125}, {'val_loss': 5618.02587890625}, {'val_loss': 5617.796875}, {'val_loss': 5617.17236328125}, {'val_loss': 5616.88671875}, {'val_loss': 5616.9033203125}, {'val_loss': 5616.47509765625}, {'val_loss': 5616.42041015625}, {'val_loss': 5617.4072265625}, {'val_loss': 5616.27783203125}, {'val_loss': 5617.03271484375}, {'val_loss': 5616.83203125}, {'val_loss': 5617.1728515625}, {'val_loss': 5617.1953125}, {'val_loss': 5618.1630859375}, {'val_loss': 5618.05322265625}, {'val_loss': 5617.83642578125}, {'val_loss': 5615.93017578125}, {'val_loss': 5616.84423828125}, {'val_loss': 5617.1103515625}, {'val_loss': 5616.7412109375}, {'val_loss': 5615.865234375}, {'val_loss': 5616.19677734375}, {'val_loss': 5616.14599609375}, {'val_loss': 5618.3427734375}, {'val_loss': 5617.12158203125}, {'val_loss': 5616.51513671875}, {'val_loss': 5615.4267578125}, {'val_loss': 5615.59912109375}, {'val_loss': 5615.396484375}, {'val_loss': 5616.40673828125}, {'val_loss': 5615.44921875}, {'val_loss': 5616.5498046875}, {'val_loss': 5615.55810546875}, {'val_loss': 5616.6123046875}, {'val_loss': 5615.33349609375}, {'val_loss': 5615.74755859375}, {'val_loss': 5614.94189453125}, {'val_loss': 5616.43798828125}, {'val_loss': 5616.31640625}, {'val_loss': 5615.21826171875}, {'val_loss': 5615.47607421875}, {'val_loss': 5616.24853515625}, {'val_loss': 5615.8994140625}, {'val_loss': 5615.6142578125}, {'val_loss': 5614.642578125}, {'val_loss': 5615.37939453125}, {'val_loss': 5614.5966796875}, {'val_loss': 5615.708984375}, {'val_loss': 5614.4814453125}, {'val_loss': 5615.20068359375}, {'val_loss': 5615.072265625}, {'val_loss': 5614.53857421875}, {'val_loss': 5614.4462890625}, {'val_loss': 5615.560546875}, {'val_loss': 5614.04345703125}, {'val_loss': 5614.96044921875}, {'val_loss': 5615.01513671875}, {'val_loss': 5615.03759765625}, {'val_loss': 5616.1689453125}, {'val_loss': 5615.22705078125}, {'val_loss': 5614.333984375}, {'val_loss': 5614.41064453125}, {'val_loss': 5615.6396484375}, {'val_loss': 5614.685546875}, {'val_loss': 5614.1953125}, {'val_loss': 5614.41259765625}, {'val_loss': 5614.80859375}, {'val_loss': 5615.0087890625}, {'val_loss': 5615.22705078125}, {'val_loss': 5613.80810546875}, {'val_loss': 5613.69921875}, {'val_loss': 5614.31494140625}, {'val_loss': 5614.63671875}, {'val_loss': 5613.48046875}, {'val_loss': 5613.18798828125}, {'val_loss': 5613.2275390625}, {'val_loss': 5613.15966796875}, {'val_loss': 5613.46630859375}, {'val_loss': 5613.302734375}, {'val_loss': 5614.12841796875}, {'val_loss': 5613.3125}, {'val_loss': 5614.0986328125}, {'val_loss': 5612.87548828125}, {'val_loss': 5613.06298828125}, {'val_loss': 5612.62109375}, {'val_loss': 5613.439453125}, {'val_loss': 5613.26708984375}, {'val_loss': 5612.7919921875}, {'val_loss': 5612.62548828125}, {'val_loss': 5613.2421875}, {'val_loss': 5614.02685546875}, {'val_loss': 5613.5771484375}, {'val_loss': 5612.24609375}, {'val_loss': 5613.2353515625}, {'val_loss': 5613.74267578125}, {'val_loss': 5613.42626953125}, {'val_loss': 5614.197265625}, {'val_loss': 5613.41455078125}, {'val_loss': 5613.02783203125}, {'val_loss': 5612.7919921875}, {'val_loss': 5611.81689453125}, {'val_loss': 5612.62939453125}, {'val_loss': 5612.90185546875}, {'val_loss': 5612.0205078125}, {'val_loss': 5612.943359375}, {'val_loss': 5611.9638671875}, {'val_loss': 5611.6474609375}, {'val_loss': 5612.314453125}, {'val_loss': 5612.1376953125}, {'val_loss': 5611.74072265625}, {'val_loss': 5612.4716796875}, {'val_loss': 5612.8251953125}, {'val_loss': 5611.5546875}, {'val_loss': 5612.5185546875}, {'val_loss': 5612.2314453125}, {'val_loss': 5611.81787109375}, {'val_loss': 5613.12841796875}, {'val_loss': 5612.30078125}, {'val_loss': 5612.23828125}, {'val_loss': 5611.46337890625}, {'val_loss': 5611.072265625}, {'val_loss': 5611.6552734375}, {'val_loss': 5611.21337890625}, {'val_loss': 5611.52685546875}, {'val_loss': 5610.7041015625}, {'val_loss': 5611.578125}, {'val_loss': 5610.60595703125}, {'val_loss': 5611.6728515625}, {'val_loss': 5611.3642578125}, {'val_loss': 5610.97216796875}, {'val_loss': 5611.3583984375}, {'val_loss': 5612.125}, {'val_loss': 5611.09814453125}, {'val_loss': 5610.66455078125}, {'val_loss': 5612.1572265625}, {'val_loss': 5611.02587890625}, {'val_loss': 5610.59326171875}, {'val_loss': 5611.65478515625}, {'val_loss': 5610.7607421875}, {'val_loss': 5610.3828125}, {'val_loss': 5611.453125}, {'val_loss': 5610.490234375}, {'val_loss': 5610.30126953125}, {'val_loss': 5609.80859375}, {'val_loss': 5609.8271484375}, {'val_loss': 5612.15478515625}, {'val_loss': 5610.18212890625}, {'val_loss': 5611.54296875}, {'val_loss': 5610.7099609375}, {'val_loss': 5609.62109375}, {'val_loss': 5609.9736328125}, {'val_loss': 5610.927734375}, {'val_loss': 5610.73681640625}, {'val_loss': 5610.060546875}, {'val_loss': 5610.55517578125}, {'val_loss': 5613.26953125}, {'val_loss': 5610.65185546875}, {'val_loss': 5610.69482421875}, {'val_loss': 5610.3046875}, {'val_loss': 5609.11767578125}, {'val_loss': 5609.8310546875}, {'val_loss': 5609.8447265625}, {'val_loss': 5609.5517578125}, {'val_loss': 5609.95703125}, {'val_loss': 5609.5498046875}, {'val_loss': 5609.51953125}, {'val_loss': 5609.83740234375}, {'val_loss': 5610.7216796875}, {'val_loss': 5608.9208984375}, {'val_loss': 5609.81494140625}, {'val_loss': 5609.12646484375}, {'val_loss': 5609.62890625}, {'val_loss': 5609.017578125}, {'val_loss': 5608.9130859375}, {'val_loss': 5609.53662109375}, {'val_loss': 5610.40478515625}, {'val_loss': 5608.60400390625}, {'val_loss': 5608.427734375}, {'val_loss': 5608.91162109375}, {'val_loss': 5609.40380859375}, {'val_loss': 5609.09130859375}, {'val_loss': 5610.37451171875}, {'val_loss': 5609.1787109375}, {'val_loss': 5609.2958984375}, {'val_loss': 5609.28466796875}, {'val_loss': 5608.439453125}, {'val_loss': 5608.24755859375}, {'val_loss': 5607.81689453125}, {'val_loss': 5607.66455078125}, {'val_loss': 5607.71337890625}, {'val_loss': 5607.53076171875}, {'val_loss': 5607.6171875}, {'val_loss': 5607.7705078125}, {'val_loss': 5607.9638671875}, {'val_loss': 5609.3544921875}, {'val_loss': 5608.2607421875}, {'val_loss': 5607.359375}, {'val_loss': 5607.5087890625}, {'val_loss': 5607.46826171875}, {'val_loss': 5607.9033203125}, {'val_loss': 5607.36865234375}, {'val_loss': 5607.921875}, {'val_loss': 5607.31005859375}, {'val_loss': 5608.83544921875}, {'val_loss': 5607.001953125}, {'val_loss': 5608.12890625}, {'val_loss': 5607.00146484375}, {'val_loss': 5606.91357421875}, {'val_loss': 5608.50732421875}, {'val_loss': 5608.28564453125}, {'val_loss': 5607.072265625}, {'val_loss': 5606.95458984375}, {'val_loss': 5606.8828125}, {'val_loss': 5607.7626953125}, {'val_loss': 5607.1513671875}, {'val_loss': 5608.13671875}, {'val_loss': 5606.47509765625}, {'val_loss': 5606.3017578125}, {'val_loss': 5607.09326171875}, {'val_loss': 5606.81787109375}, {'val_loss': 5607.5625}, {'val_loss': 5606.19482421875}, {'val_loss': 5607.07958984375}, {'val_loss': 5606.4814453125}, {'val_loss': 5606.6337890625}, {'val_loss': 5607.57421875}, {'val_loss': 5606.73046875}, {'val_loss': 5606.91162109375}, {'val_loss': 5605.7939453125}, {'val_loss': 5606.79150390625}, {'val_loss': 5606.0712890625}, {'val_loss': 5605.625}, {'val_loss': 5607.2880859375}, {'val_loss': 5606.29736328125}, {'val_loss': 5606.8212890625}, {'val_loss': 5606.744140625}, {'val_loss': 5606.7900390625}, {'val_loss': 5607.15771484375}, {'val_loss': 5605.77490234375}, {'val_loss': 5606.3349609375}, {'val_loss': 5605.33544921875}, {'val_loss': 5605.65869140625}, {'val_loss': 5605.865234375}, {'val_loss': 5606.64013671875}, {'val_loss': 5607.251953125}, {'val_loss': 5605.2919921875}, {'val_loss': 5605.9091796875}, {'val_loss': 5605.52685546875}, {'val_loss': 5605.7197265625}, {'val_loss': 5605.59814453125}, {'val_loss': 5605.201171875}, {'val_loss': 5605.1953125}, {'val_loss': 5605.94921875}, {'val_loss': 5604.98486328125}, {'val_loss': 5605.75439453125}, {'val_loss': 5605.28271484375}, {'val_loss': 5604.873046875}, {'val_loss': 5606.181640625}, {'val_loss': 5604.615234375}, {'val_loss': 5604.5537109375}, {'val_loss': 5605.95068359375}, {'val_loss': 5604.56103515625}, {'val_loss': 5605.22216796875}, {'val_loss': 5604.85107421875}, {'val_loss': 5604.9189453125}, {'val_loss': 5605.07177734375}, {'val_loss': 5604.21337890625}, {'val_loss': 5604.80615234375}, {'val_loss': 5604.09814453125}, {'val_loss': 5603.8408203125}, {'val_loss': 5604.251953125}, {'val_loss': 5604.36328125}, {'val_loss': 5604.6103515625}, {'val_loss': 5603.9658203125}, {'val_loss': 5604.37255859375}, {'val_loss': 5604.076171875}, {'val_loss': 5604.28662109375}, {'val_loss': 5603.396484375}, {'val_loss': 5605.0869140625}, {'val_loss': 5603.66259765625}, {'val_loss': 5603.78173828125}, {'val_loss': 5604.52490234375}, {'val_loss': 5603.53271484375}, {'val_loss': 5604.15966796875}, {'val_loss': 5604.57373046875}, {'val_loss': 5603.955078125}, {'val_loss': 5605.8408203125}, {'val_loss': 5603.9052734375}, {'val_loss': 5603.05078125}, {'val_loss': 5603.982421875}, {'val_loss': 5605.41845703125}, {'val_loss': 5604.361328125}, {'val_loss': 5602.97021484375}, {'val_loss': 5603.14013671875}, {'val_loss': 5603.28173828125}, {'val_loss': 5603.3505859375}, {'val_loss': 5603.923828125}, {'val_loss': 5603.9794921875}, {'val_loss': 5603.43408203125}, {'val_loss': 5603.02978515625}, {'val_loss': 5602.7216796875}, {'val_loss': 5603.09326171875}, {'val_loss': 5603.60205078125}, {'val_loss': 5603.75}, {'val_loss': 5604.09619140625}, {'val_loss': 5602.7978515625}, {'val_loss': 5602.75732421875}, {'val_loss': 5602.06591796875}, {'val_loss': 5603.86767578125}, {'val_loss': 5601.90478515625}, {'val_loss': 5602.09912109375}, {'val_loss': 5602.4677734375}, {'val_loss': 5604.31591796875}, {'val_loss': 5602.5869140625}, {'val_loss': 5603.09130859375}, {'val_loss': 5601.97119140625}, {'val_loss': 5602.40380859375}, {'val_loss': 5603.46240234375}, {'val_loss': 5603.27783203125}, {'val_loss': 5602.080078125}, {'val_loss': 5601.8310546875}, {'val_loss': 5601.62109375}, {'val_loss': 5601.6357421875}, {'val_loss': 5602.37646484375}, {'val_loss': 5602.31103515625}, {'val_loss': 5601.2314453125}, {'val_loss': 5601.6875}, {'val_loss': 5602.0458984375}, {'val_loss': 5602.22216796875}, {'val_loss': 5600.97509765625}, {'val_loss': 5601.50244140625}, {'val_loss': 5601.35009765625}, {'val_loss': 5601.09716796875}, {'val_loss': 5600.96044921875}, {'val_loss': 5600.84619140625}, {'val_loss': 5601.0263671875}, {'val_loss': 5602.21826171875}, {'val_loss': 5600.765625}, {'val_loss': 5601.49072265625}, {'val_loss': 5602.28369140625}, {'val_loss': 5602.0380859375}, {'val_loss': 5601.4228515625}, {'val_loss': 5601.234375}, {'val_loss': 5601.25341796875}, {'val_loss': 5600.37939453125}, {'val_loss': 5601.51123046875}, {'val_loss': 5600.71044921875}, {'val_loss': 5601.72119140625}, {'val_loss': 5601.44140625}, {'val_loss': 5601.0791015625}, {'val_loss': 5601.81982421875}, {'val_loss': 5602.27099609375}, {'val_loss': 5601.50537109375}, {'val_loss': 5600.6171875}, {'val_loss': 5600.29296875}, {'val_loss': 5600.5302734375}, {'val_loss': 5601.44189453125}, {'val_loss': 5600.4736328125}, {'val_loss': 5601.060546875}, {'val_loss': 5599.58154296875}, {'val_loss': 5599.78369140625}, {'val_loss': 5599.84228515625}, {'val_loss': 5599.87353515625}, {'val_loss': 5599.92822265625}, {'val_loss': 5599.5732421875}, {'val_loss': 5599.79296875}, {'val_loss': 5599.861328125}, {'val_loss': 5601.34619140625}, {'val_loss': 5600.8017578125}, {'val_loss': 5599.80517578125}, {'val_loss': 5599.0537109375}, {'val_loss': 5599.86767578125}, {'val_loss': 5599.22216796875}, {'val_loss': 5599.1572265625}, {'val_loss': 5600.015625}, {'val_loss': 5599.59619140625}, {'val_loss': 5598.73486328125}, {'val_loss': 5599.6005859375}, {'val_loss': 5599.419921875}, {'val_loss': 5599.56103515625}, {'val_loss': 5599.5732421875}, {'val_loss': 5599.33154296875}, {'val_loss': 5599.87548828125}, {'val_loss': 5599.7060546875}, {'val_loss': 5600.21533203125}, {'val_loss': 5598.6728515625}, {'val_loss': 5599.205078125}, {'val_loss': 5598.54541015625}, {'val_loss': 5598.36376953125}, {'val_loss': 5600.61328125}, {'val_loss': 5598.9296875}, {'val_loss': 5599.40283203125}, {'val_loss': 5598.59619140625}, {'val_loss': 5598.1396484375}, {'val_loss': 5598.7080078125}, {'val_loss': 5598.6025390625}, {'val_loss': 5598.8671875}, {'val_loss': 5597.87744140625}, {'val_loss': 5598.548828125}, {'val_loss': 5598.4697265625}, {'val_loss': 5598.16796875}, {'val_loss': 5598.20068359375}, {'val_loss': 5597.62353515625}, {'val_loss': 5597.5224609375}, {'val_loss': 5597.4248046875}, {'val_loss': 5598.05078125}, {'val_loss': 5597.45703125}, {'val_loss': 5597.5732421875}, {'val_loss': 5597.24755859375}, {'val_loss': 5598.10546875}, {'val_loss': 5597.5078125}, {'val_loss': 5597.81640625}, {'val_loss': 5597.05517578125}, {'val_loss': 5598.2587890625}, {'val_loss': 5598.103515625}, {'val_loss': 5598.189453125}, {'val_loss': 5597.15087890625}, {'val_loss': 5598.59326171875}, {'val_loss': 5598.34326171875}, {'val_loss': 5596.73486328125}, {'val_loss': 5596.978515625}, {'val_loss': 5597.31201171875}, {'val_loss': 5596.826171875}, {'val_loss': 5596.515625}, {'val_loss': 5597.70068359375}, {'val_loss': 5597.03955078125}, {'val_loss': 5598.7412109375}, {'val_loss': 5596.68798828125}, {'val_loss': 5597.6103515625}, {'val_loss': 5598.52587890625}, {'val_loss': 5597.8974609375}, {'val_loss': 5596.48095703125}, {'val_loss': 5598.5791015625}, {'val_loss': 5597.453125}, {'val_loss': 5596.82373046875}, {'val_loss': 5596.8046875}, {'val_loss': 5597.4892578125}, {'val_loss': 5597.21240234375}, {'val_loss': 5596.45068359375}, {'val_loss': 5597.04931640625}, {'val_loss': 5596.6025390625}, {'val_loss': 5595.73046875}, {'val_loss': 5597.05322265625}, {'val_loss': 5596.61767578125}, {'val_loss': 5596.22314453125}, {'val_loss': 5597.07373046875}, {'val_loss': 5595.52099609375}, {'val_loss': 5596.8955078125}, {'val_loss': 5596.86328125}, {'val_loss': 5595.494140625}, {'val_loss': 5596.03662109375}, {'val_loss': 5597.96240234375}, {'val_loss': 5595.96923828125}, {'val_loss': 5596.46142578125}, {'val_loss': 5596.3955078125}, {'val_loss': 5595.48046875}, {'val_loss': 5595.64990234375}, {'val_loss': 5595.07568359375}, {'val_loss': 5595.70458984375}, {'val_loss': 5595.55517578125}, {'val_loss': 5595.25048828125}, {'val_loss': 5596.12744140625}, {'val_loss': 5595.34130859375}, {'val_loss': 5595.14208984375}, {'val_loss': 5594.6455078125}, {'val_loss': 5595.7705078125}, {'val_loss': 5595.7978515625}, {'val_loss': 5594.4599609375}, {'val_loss': 5595.4921875}, {'val_loss': 5595.791015625}, {'val_loss': 5594.7939453125}, {'val_loss': 5595.05615234375}, {'val_loss': 5594.748046875}, {'val_loss': 5594.2626953125}, {'val_loss': 5594.15087890625}, {'val_loss': 5595.12451171875}, {'val_loss': 5596.51171875}, {'val_loss': 5594.24462890625}, {'val_loss': 5596.06494140625}, {'val_loss': 5595.013671875}, {'val_loss': 5594.5927734375}, {'val_loss': 5594.67578125}, {'val_loss': 5594.22314453125}, {'val_loss': 5594.7177734375}, {'val_loss': 5594.84228515625}, {'val_loss': 5594.857421875}, {'val_loss': 5594.62744140625}, {'val_loss': 5593.5478515625}, {'val_loss': 5593.853515625}, {'val_loss': 5595.28564453125}, {'val_loss': 5593.90380859375}, {'val_loss': 5594.80908203125}, {'val_loss': 5594.5380859375}, {'val_loss': 5593.87353515625}, {'val_loss': 5594.0302734375}, {'val_loss': 5594.74365234375}, {'val_loss': 5593.98681640625}, {'val_loss': 5593.9814453125}, {'val_loss': 5593.9892578125}, {'val_loss': 5594.4921875}, {'val_loss': 5595.78857421875}, {'val_loss': 5594.05126953125}, {'val_loss': 5595.80712890625}, {'val_loss': 5593.67431640625}, {'val_loss': 5593.0}, {'val_loss': 5593.44873046875}, {'val_loss': 5593.9150390625}, {'val_loss': 5593.51904296875}, {'val_loss': 5595.8349609375}, {'val_loss': 5593.70654296875}, {'val_loss': 5593.548828125}, {'val_loss': 5592.8935546875}, {'val_loss': 5594.21826171875}, {'val_loss': 5593.484375}, {'val_loss': 5592.65380859375}, {'val_loss': 5593.01708984375}, {'val_loss': 5593.2724609375}, {'val_loss': 5593.185546875}, {'val_loss': 5593.35107421875}, {'val_loss': 5592.81787109375}, {'val_loss': 5593.560546875}, {'val_loss': 5591.9638671875}, {'val_loss': 5591.89892578125}, {'val_loss': 5592.28564453125}, {'val_loss': 5593.59423828125}, {'val_loss': 5593.44921875}, {'val_loss': 5591.953125}, {'val_loss': 5592.7333984375}, {'val_loss': 5592.5771484375}, {'val_loss': 5592.8212890625}, {'val_loss': 5592.32373046875}, {'val_loss': 5592.3486328125}, {'val_loss': 5591.72119140625}, {'val_loss': 5592.6953125}, {'val_loss': 5592.59619140625}, {'val_loss': 5591.25}, {'val_loss': 5592.42626953125}, {'val_loss': 5592.4501953125}, {'val_loss': 5592.22216796875}, {'val_loss': 5592.0458984375}, {'val_loss': 5591.09326171875}, {'val_loss': 5591.05712890625}, {'val_loss': 5592.24951171875}, {'val_loss': 5592.1142578125}, {'val_loss': 5591.75537109375}, {'val_loss': 5592.4521484375}, {'val_loss': 5592.01171875}, {'val_loss': 5591.58154296875}, {'val_loss': 5591.0419921875}, {'val_loss': 5592.2119140625}, {'val_loss': 5590.7392578125}, {'val_loss': 5590.87646484375}, {'val_loss': 5591.70849609375}, {'val_loss': 5591.94189453125}, {'val_loss': 5591.9013671875}, {'val_loss': 5592.3564453125}, {'val_loss': 5590.99609375}, {'val_loss': 5593.61962890625}, {'val_loss': 5592.3994140625}, {'val_loss': 5591.2861328125}, {'val_loss': 5591.40185546875}, {'val_loss': 5591.0517578125}, {'val_loss': 5590.42236328125}, {'val_loss': 5590.26513671875}, {'val_loss': 5591.044921875}, {'val_loss': 5590.21728515625}, {'val_loss': 5590.47900390625}, {'val_loss': 5590.56005859375}, {'val_loss': 5590.39404296875}, {'val_loss': 5590.44384765625}, {'val_loss': 5592.0302734375}, {'val_loss': 5590.3349609375}, {'val_loss': 5590.08935546875}, {'val_loss': 5589.7607421875}, {'val_loss': 5589.6064453125}, {'val_loss': 5589.5439453125}, {'val_loss': 5590.9375}, {'val_loss': 5590.2783203125}, {'val_loss': 5589.9287109375}, {'val_loss': 5590.12158203125}, {'val_loss': 5591.240234375}, {'val_loss': 5590.76318359375}, {'val_loss': 5589.62646484375}, {'val_loss': 5589.046875}, {'val_loss': 5589.5302734375}, {'val_loss': 5589.69482421875}, {'val_loss': 5589.81787109375}, {'val_loss': 5589.16845703125}, {'val_loss': 5589.9921875}, {'val_loss': 5590.1328125}, {'val_loss': 5591.044921875}, {'val_loss': 5588.9501953125}, {'val_loss': 5589.0546875}, {'val_loss': 5588.7646484375}, {'val_loss': 5589.05615234375}, {'val_loss': 5589.57373046875}, {'val_loss': 5590.65869140625}, {'val_loss': 5591.5791015625}, {'val_loss': 5588.509765625}, {'val_loss': 5589.1708984375}, {'val_loss': 5588.751953125}, {'val_loss': 5589.068359375}, {'val_loss': 5590.5791015625}, {'val_loss': 5589.9677734375}, {'val_loss': 5589.24609375}, {'val_loss': 5588.76123046875}, {'val_loss': 5588.5341796875}, {'val_loss': 5588.7919921875}, {'val_loss': 5589.4189453125}, {'val_loss': 5588.93505859375}, {'val_loss': 5588.58154296875}, {'val_loss': 5588.27392578125}, {'val_loss': 5588.083984375}, {'val_loss': 5587.72021484375}, {'val_loss': 5587.5380859375}, {'val_loss': 5588.5107421875}, {'val_loss': 5590.09814453125}, {'val_loss': 5588.40966796875}, {'val_loss': 5588.41259765625}, {'val_loss': 5587.3564453125}, {'val_loss': 5587.31640625}, {'val_loss': 5588.12255859375}, {'val_loss': 5587.548828125}, {'val_loss': 5588.4189453125}, {'val_loss': 5589.0927734375}, {'val_loss': 5588.40966796875}, {'val_loss': 5588.31005859375}, {'val_loss': 5587.18408203125}, {'val_loss': 5587.3427734375}, {'val_loss': 5587.95263671875}, {'val_loss': 5588.0625}, {'val_loss': 5587.09521484375}, {'val_loss': 5587.5498046875}, {'val_loss': 5588.310546875}, {'val_loss': 5586.978515625}, {'val_loss': 5586.90673828125}, {'val_loss': 5587.171875}, {'val_loss': 5586.8388671875}, {'val_loss': 5586.73828125}, {'val_loss': 5587.6669921875}, {'val_loss': 5587.12060546875}, {'val_loss': 5586.7607421875}, {'val_loss': 5587.736328125}, {'val_loss': 5587.3642578125}, {'val_loss': 5587.875}, {'val_loss': 5587.34912109375}, {'val_loss': 5587.0771484375}, {'val_loss': 5586.23486328125}, {'val_loss': 5587.24072265625}, {'val_loss': 5587.2275390625}, {'val_loss': 5585.90380859375}, {'val_loss': 5588.0400390625}, {'val_loss': 5587.31787109375}, {'val_loss': 5586.80810546875}, {'val_loss': 5587.07177734375}, {'val_loss': 5587.9541015625}, {'val_loss': 5588.52490234375}, {'val_loss': 5585.9375}, {'val_loss': 5585.59130859375}, {'val_loss': 5585.63427734375}, {'val_loss': 5587.18505859375}, {'val_loss': 5586.0263671875}, {'val_loss': 5587.02099609375}, {'val_loss': 5586.01904296875}, {'val_loss': 5585.9169921875}, {'val_loss': 5585.72119140625}, {'val_loss': 5585.7578125}, {'val_loss': 5585.73486328125}, {'val_loss': 5586.43212890625}, {'val_loss': 5585.16845703125}, {'val_loss': 5586.751953125}, {'val_loss': 5586.65673828125}, {'val_loss': 5586.37158203125}, {'val_loss': 5587.19482421875}, {'val_loss': 5585.35791015625}, {'val_loss': 5586.7119140625}, {'val_loss': 5585.015625}, {'val_loss': 5586.486328125}, {'val_loss': 5584.80126953125}, {'val_loss': 5584.78759765625}, {'val_loss': 5585.3203125}, {'val_loss': 5585.384765625}, {'val_loss': 5585.50634765625}, {'val_loss': 5585.45263671875}, {'val_loss': 5584.982421875}, {'val_loss': 5586.10400390625}, {'val_loss': 5584.9052734375}, {'val_loss': 5585.1953125}, {'val_loss': 5584.7919921875}, {'val_loss': 5585.12744140625}, {'val_loss': 5584.41796875}, {'val_loss': 5584.04296875}, {'val_loss': 5584.86181640625}, {'val_loss': 5585.83740234375}, {'val_loss': 5584.62109375}, {'val_loss': 5584.15185546875}, {'val_loss': 5584.22412109375}, {'val_loss': 5583.93505859375}, {'val_loss': 5585.02685546875}, {'val_loss': 5584.111328125}, {'val_loss': 5584.27783203125}, {'val_loss': 5584.40185546875}, {'val_loss': 5585.9912109375}, {'val_loss': 5583.85107421875}, {'val_loss': 5583.57958984375}, {'val_loss': 5583.28662109375}, {'val_loss': 5584.95458984375}, {'val_loss': 5583.85546875}, {'val_loss': 5583.38671875}, {'val_loss': 5583.15087890625}, {'val_loss': 5583.69189453125}, {'val_loss': 5585.4580078125}, {'val_loss': 5583.48876953125}, {'val_loss': 5583.7666015625}, {'val_loss': 5583.59033203125}, {'val_loss': 5583.26904296875}, {'val_loss': 5583.2724609375}, {'val_loss': 5583.74755859375}, {'val_loss': 5584.64404296875}, {'val_loss': 5584.70068359375}, {'val_loss': 5583.6962890625}, {'val_loss': 5584.4794921875}, {'val_loss': 5582.87646484375}, {'val_loss': 5583.65771484375}, {'val_loss': 5583.19677734375}, {'val_loss': 5582.52294921875}, {'val_loss': 5583.53759765625}, {'val_loss': 5583.45703125}, {'val_loss': 5584.361328125}, {'val_loss': 5584.390625}, {'val_loss': 5583.2041015625}, {'val_loss': 5584.31201171875}, {'val_loss': 5582.5107421875}, {'val_loss': 5582.33740234375}, {'val_loss': 5582.73291015625}, {'val_loss': 5583.5810546875}, {'val_loss': 5583.02392578125}, {'val_loss': 5584.1962890625}, {'val_loss': 5582.00439453125}, {'val_loss': 5581.7314453125}, {'val_loss': 5582.15576171875}, {'val_loss': 5582.39990234375}, {'val_loss': 5582.46728515625}, {'val_loss': 5584.2880859375}, {'val_loss': 5582.6611328125}, {'val_loss': 5584.29931640625}, {'val_loss': 5581.86962890625}, {'val_loss': 5581.615234375}, {'val_loss': 5582.373046875}, {'val_loss': 5581.61962890625}, {'val_loss': 5581.5947265625}, {'val_loss': 5582.09228515625}, {'val_loss': 5582.1962890625}, {'val_loss': 5582.85546875}, {'val_loss': 5583.64453125}, {'val_loss': 5583.62060546875}, {'val_loss': 5581.1630859375}, {'val_loss': 5581.94091796875}, {'val_loss': 5581.134765625}, {'val_loss': 5581.23681640625}, {'val_loss': 5582.1982421875}, {'val_loss': 5580.9853515625}, {'val_loss': 5581.9189453125}, {'val_loss': 5582.111328125}, {'val_loss': 5581.01708984375}, {'val_loss': 5580.94482421875}, {'val_loss': 5580.85595703125}, {'val_loss': 5581.798828125}, {'val_loss': 5581.73046875}, {'val_loss': 5581.333984375}, {'val_loss': 5582.82958984375}, {'val_loss': 5580.53369140625}, {'val_loss': 5580.7177734375}, {'val_loss': 5580.8349609375}, {'val_loss': 5581.57177734375}, {'val_loss': 5582.57421875}, {'val_loss': 5580.62158203125}, {'val_loss': 5581.30078125}, {'val_loss': 5580.3505859375}, {'val_loss': 5580.3212890625}, {'val_loss': 5579.9169921875}, {'val_loss': 5580.56494140625}, {'val_loss': 5581.56298828125}, {'val_loss': 5579.96533203125}, {'val_loss': 5582.09228515625}, {'val_loss': 5580.56982421875}, {'val_loss': 5579.89453125}, {'val_loss': 5581.5947265625}, {'val_loss': 5580.2099609375}, {'val_loss': 5579.455078125}, {'val_loss': 5579.369140625}, {'val_loss': 5579.818359375}, {'val_loss': 5579.98876953125}, {'val_loss': 5579.39599609375}, {'val_loss': 5579.3671875}, {'val_loss': 5579.12451171875}, {'val_loss': 5579.0888671875}, {'val_loss': 5579.3330078125}, {'val_loss': 5579.666015625}, {'val_loss': 5579.740234375}, {'val_loss': 5581.15673828125}, {'val_loss': 5580.15087890625}, {'val_loss': 5578.931640625}, {'val_loss': 5579.513671875}, {'val_loss': 5579.5751953125}, {'val_loss': 5580.49609375}, {'val_loss': 5580.25927734375}, {'val_loss': 5580.10107421875}, {'val_loss': 5578.81884765625}, {'val_loss': 5578.5712890625}, {'val_loss': 5581.6142578125}, {'val_loss': 5578.7861328125}, {'val_loss': 5578.98828125}, {'val_loss': 5579.4033203125}, {'val_loss': 5579.0888671875}, {'val_loss': 5578.13818359375}, {'val_loss': 5579.671875}, {'val_loss': 5578.3955078125}, {'val_loss': 5578.87060546875}, {'val_loss': 5579.24853515625}, {'val_loss': 5578.90869140625}, {'val_loss': 5578.98828125}, {'val_loss': 5578.43408203125}, {'val_loss': 5577.833984375}, {'val_loss': 5578.619140625}, {'val_loss': 5579.38427734375}, {'val_loss': 5578.314453125}, {'val_loss': 5577.60205078125}, {'val_loss': 5578.576171875}, {'val_loss': 5579.5458984375}, {'val_loss': 5578.66259765625}, {'val_loss': 5578.28955078125}, {'val_loss': 5579.00537109375}, {'val_loss': 5578.4267578125}, {'val_loss': 5578.4619140625}, {'val_loss': 5578.46142578125}, {'val_loss': 5578.4814453125}, {'val_loss': 5578.3408203125}, {'val_loss': 5577.07373046875}, {'val_loss': 5577.7802734375}, {'val_loss': 5579.3974609375}, {'val_loss': 5577.19287109375}, {'val_loss': 5578.94189453125}, {'val_loss': 5578.28857421875}, {'val_loss': 5577.12060546875}, {'val_loss': 5576.7900390625}, {'val_loss': 5576.9853515625}, {'val_loss': 5576.646484375}, {'val_loss': 5576.5791015625}, {'val_loss': 5577.79541015625}, {'val_loss': 5577.248046875}, {'val_loss': 5576.8330078125}, {'val_loss': 5576.57958984375}, {'val_loss': 5577.3017578125}, {'val_loss': 5576.53173828125}, {'val_loss': 5576.9228515625}, {'val_loss': 5576.62158203125}, {'val_loss': 5576.17236328125}, {'val_loss': 5576.671875}, {'val_loss': 5576.69677734375}, {'val_loss': 5576.48046875}, {'val_loss': 5577.57568359375}, {'val_loss': 5576.2216796875}, {'val_loss': 5576.6630859375}, {'val_loss': 5576.02783203125}, {'val_loss': 5577.5703125}, {'val_loss': 5576.75146484375}, {'val_loss': 5576.7587890625}, {'val_loss': 5577.83349609375}, {'val_loss': 5576.66455078125}, {'val_loss': 5575.67626953125}, {'val_loss': 5576.6728515625}, {'val_loss': 5575.75048828125}, {'val_loss': 5576.0322265625}, {'val_loss': 5576.509765625}, {'val_loss': 5576.33154296875}, {'val_loss': 5576.16259765625}, {'val_loss': 5575.98876953125}, {'val_loss': 5576.33837890625}, {'val_loss': 5575.42626953125}, {'val_loss': 5576.2158203125}, {'val_loss': 5576.04296875}, {'val_loss': 5577.25537109375}, {'val_loss': 5575.4091796875}, {'val_loss': 5575.76171875}, {'val_loss': 5575.43798828125}, {'val_loss': 5576.8974609375}, {'val_loss': 5575.6474609375}, {'val_loss': 5575.171875}, {'val_loss': 5576.49365234375}, {'val_loss': 5575.7666015625}, {'val_loss': 5576.177734375}, {'val_loss': 5575.59716796875}, {'val_loss': 5574.78369140625}, {'val_loss': 5576.814453125}, {'val_loss': 5575.3955078125}, {'val_loss': 5575.68408203125}, {'val_loss': 5576.2958984375}, {'val_loss': 5576.10107421875}, {'val_loss': 5576.0283203125}, {'val_loss': 5575.1875}, {'val_loss': 5575.2626953125}, {'val_loss': 5574.36572265625}, {'val_loss': 5574.435546875}, {'val_loss': 5575.03466796875}, {'val_loss': 5574.1767578125}, {'val_loss': 5573.923828125}, {'val_loss': 5574.41259765625}, {'val_loss': 5574.271484375}, {'val_loss': 5575.5419921875}, {'val_loss': 5574.53759765625}, {'val_loss': 5575.361328125}, {'val_loss': 5574.12060546875}, {'val_loss': 5574.96728515625}, {'val_loss': 5576.01318359375}, {'val_loss': 5575.5537109375}, {'val_loss': 5574.2978515625}, {'val_loss': 5573.8671875}, {'val_loss': 5574.8583984375}, {'val_loss': 5574.3642578125}, {'val_loss': 5573.22705078125}, {'val_loss': 5573.61865234375}, {'val_loss': 5573.94140625}, {'val_loss': 5573.71044921875}, {'val_loss': 5573.4482421875}, {'val_loss': 5574.626953125}, {'val_loss': 5574.68701171875}, {'val_loss': 5573.7666015625}, {'val_loss': 5573.51171875}, {'val_loss': 5572.88671875}, {'val_loss': 5573.9228515625}, {'val_loss': 5572.7607421875}, {'val_loss': 5572.8271484375}, {'val_loss': 5574.60400390625}, {'val_loss': 5574.74658203125}, {'val_loss': 5572.697265625}, {'val_loss': 5572.88037109375}, {'val_loss': 5573.630859375}, {'val_loss': 5574.1416015625}, {'val_loss': 5572.8876953125}, {'val_loss': 5572.75}, {'val_loss': 5572.25390625}, {'val_loss': 5572.5341796875}, {'val_loss': 5573.435546875}, {'val_loss': 5572.111328125}, {'val_loss': 5572.833984375}, {'val_loss': 5572.98681640625}, {'val_loss': 5573.69189453125}, {'val_loss': 5572.70458984375}, {'val_loss': 5573.84130859375}, {'val_loss': 5572.31103515625}, {'val_loss': 5572.62158203125}, {'val_loss': 5572.74560546875}, {'val_loss': 5572.18212890625}, {'val_loss': 5572.77685546875}, {'val_loss': 5573.31884765625}, {'val_loss': 5574.857421875}, {'val_loss': 5571.8203125}, {'val_loss': 5572.26171875}, {'val_loss': 5572.06201171875}, {'val_loss': 5571.66162109375}, {'val_loss': 5572.75537109375}, {'val_loss': 5571.7392578125}, {'val_loss': 5571.6142578125}, {'val_loss': 5571.57373046875}, {'val_loss': 5572.458984375}, {'val_loss': 5572.42041015625}, {'val_loss': 5571.021484375}, {'val_loss': 5572.58544921875}, {'val_loss': 5571.1953125}, {'val_loss': 5573.15576171875}, {'val_loss': 5572.505859375}, {'val_loss': 5572.1669921875}, {'val_loss': 5571.54736328125}, {'val_loss': 5570.95703125}, {'val_loss': 5571.42236328125}, {'val_loss': 5571.6396484375}, {'val_loss': 5573.09814453125}, {'val_loss': 5571.1650390625}, {'val_loss': 5571.54931640625}, {'val_loss': 5571.33935546875}, {'val_loss': 5570.56005859375}, {'val_loss': 5571.14794921875}, {'val_loss': 5571.12646484375}, {'val_loss': 5571.1455078125}, {'val_loss': 5570.25439453125}, {'val_loss': 5571.31640625}, {'val_loss': 5571.8369140625}, {'val_loss': 5571.6064453125}, {'val_loss': 5571.419921875}, {'val_loss': 5571.3623046875}, {'val_loss': 5571.2099609375}, {'val_loss': 5571.1328125}, {'val_loss': 5571.12353515625}, {'val_loss': 5571.02392578125}, {'val_loss': 5570.9755859375}, {'val_loss': 5571.03271484375}, {'val_loss': 5571.02392578125}, {'val_loss': 5571.00244140625}, {'val_loss': 5571.017578125}, {'val_loss': 5571.00732421875}, {'val_loss': 5570.9697265625}, {'val_loss': 5571.0087890625}, {'val_loss': 5571.04736328125}, {'val_loss': 5571.04931640625}, {'val_loss': 5571.04931640625}, {'val_loss': 5571.009765625}, {'val_loss': 5571.0}, {'val_loss': 5571.03955078125}, {'val_loss': 5571.02099609375}, {'val_loss': 5571.0087890625}, {'val_loss': 5571.00927734375}, {'val_loss': 5571.02978515625}, {'val_loss': 5570.99072265625}, {'val_loss': 5570.9833984375}, {'val_loss': 5571.03955078125}, {'val_loss': 5571.134765625}, {'val_loss': 5571.0751953125}, {'val_loss': 5571.11328125}, {'val_loss': 5571.0322265625}, {'val_loss': 5571.03271484375}, {'val_loss': 5571.0419921875}, {'val_loss': 5571.0146484375}, {'val_loss': 5571.0849609375}, {'val_loss': 5571.05615234375}, {'val_loss': 5571.08544921875}, {'val_loss': 5571.0966796875}, {'val_loss': 5571.05517578125}, {'val_loss': 5571.0810546875}, {'val_loss': 5571.09912109375}, {'val_loss': 5571.048828125}, {'val_loss': 5571.0478515625}, {'val_loss': 5571.048828125}, {'val_loss': 5571.03857421875}, {'val_loss': 5571.0498046875}, {'val_loss': 5570.9912109375}, {'val_loss': 5571.04736328125}, {'val_loss': 5571.06396484375}, {'val_loss': 5571.0244140625}, {'val_loss': 5570.994140625}, {'val_loss': 5570.984375}, {'val_loss': 5570.9755859375}, {'val_loss': 5571.05322265625}, {'val_loss': 5571.013671875}, {'val_loss': 5571.00537109375}, {'val_loss': 5571.02587890625}, {'val_loss': 5571.04736328125}, {'val_loss': 5571.06689453125}, {'val_loss': 5571.1337890625}, {'val_loss': 5571.01904296875}, {'val_loss': 5571.076171875}, {'val_loss': 5571.13232421875}, {'val_loss': 5571.09130859375}, {'val_loss': 5571.0703125}, {'val_loss': 5571.1103515625}, {'val_loss': 5571.11181640625}, {'val_loss': 5571.1611328125}, {'val_loss': 5571.08203125}, {'val_loss': 5571.06396484375}, {'val_loss': 5571.04345703125}, {'val_loss': 5571.064453125}, {'val_loss': 5571.04345703125}, {'val_loss': 5571.06298828125}, {'val_loss': 5570.99462890625}, {'val_loss': 5570.97705078125}, {'val_loss': 5570.9677734375}, {'val_loss': 5570.98291015625}, {'val_loss': 5570.947265625}, {'val_loss': 5570.9462890625}, {'val_loss': 5570.99462890625}, {'val_loss': 5571.04150390625}, {'val_loss': 5571.01953125}, {'val_loss': 5571.00048828125}, {'val_loss': 5570.9912109375}, {'val_loss': 5571.001953125}, {'val_loss': 5571.048828125}, {'val_loss': 5571.0087890625}, {'val_loss': 5571.05517578125}, {'val_loss': 5571.05322265625}, {'val_loss': 5571.0146484375}, {'val_loss': 5571.044921875}, {'val_loss': 5571.0458984375}, {'val_loss': 5570.99658203125}, {'val_loss': 5570.9716796875}, {'val_loss': 5570.99560546875}, {'val_loss': 5570.94189453125}, {'val_loss': 5570.9541015625}, {'val_loss': 5570.9892578125}, {'val_loss': 5570.990234375}, {'val_loss': 5570.97900390625}, {'val_loss': 5570.96923828125}, {'val_loss': 5570.9462890625}, {'val_loss': 5570.96533203125}, {'val_loss': 5570.947265625}, {'val_loss': 5571.021484375}, {'val_loss': 5571.00048828125}, {'val_loss': 5571.021484375}, {'val_loss': 5571.03759765625}, {'val_loss': 5570.98486328125}, {'val_loss': 5570.97607421875}, {'val_loss': 5570.96533203125}, {'val_loss': 5571.00048828125}, {'val_loss': 5571.05810546875}, {'val_loss': 5571.056640625}, {'val_loss': 5570.9697265625}, {'val_loss': 5571.0166015625}, {'val_loss': 5570.99560546875}, {'val_loss': 5571.02099609375}, {'val_loss': 5571.02099609375}, {'val_loss': 5571.0322265625}, {'val_loss': 5571.05126953125}, {'val_loss': 5570.97900390625}, {'val_loss': 5570.93994140625}, {'val_loss': 5570.94091796875}, {'val_loss': 5570.978515625}, {'val_loss': 5570.9873046875}, {'val_loss': 5570.98828125}, {'val_loss': 5571.0087890625}, {'val_loss': 5570.97705078125}, {'val_loss': 5570.95703125}, {'val_loss': 5570.92626953125}, {'val_loss': 5570.9521484375}, {'val_loss': 5570.90380859375}, {'val_loss': 5570.90576171875}, {'val_loss': 5570.923828125}, {'val_loss': 5570.92431640625}, {'val_loss': 5570.8955078125}, {'val_loss': 5570.9716796875}, {'val_loss': 5570.9619140625}, {'val_loss': 5570.9619140625}, {'val_loss': 5570.919921875}, {'val_loss': 5570.9296875}, {'val_loss': 5570.96630859375}, {'val_loss': 5570.9287109375}, {'val_loss': 5570.9169921875}, {'val_loss': 5570.90869140625}, {'val_loss': 5570.88037109375}, {'val_loss': 5570.9560546875}, {'val_loss': 5570.95654296875}, {'val_loss': 5570.955078125}, {'val_loss': 5570.95458984375}, {'val_loss': 5570.9521484375}, {'val_loss': 5570.953125}, {'val_loss': 5570.9501953125}, {'val_loss': 5570.95068359375}, {'val_loss': 5570.94873046875}, {'val_loss': 5570.947265625}, {'val_loss': 5570.94677734375}, {'val_loss': 5570.9462890625}, {'val_loss': 5570.9453125}, {'val_loss': 5570.94384765625}, {'val_loss': 5570.943359375}, {'val_loss': 5570.94287109375}, {'val_loss': 5570.94140625}, {'val_loss': 5570.93798828125}, {'val_loss': 5570.93896484375}, {'val_loss': 5570.93603515625}, {'val_loss': 5570.93505859375}, {'val_loss': 5570.93408203125}, {'val_loss': 5570.93505859375}, {'val_loss': 5570.93359375}, {'val_loss': 5570.931640625}, {'val_loss': 5570.93212890625}, {'val_loss': 5570.93115234375}, {'val_loss': 5570.93017578125}, {'val_loss': 5570.9287109375}, {'val_loss': 5570.93115234375}, {'val_loss': 5570.931640625}, {'val_loss': 5570.93017578125}, {'val_loss': 5570.9287109375}, {'val_loss': 5570.9287109375}, {'val_loss': 5570.93115234375}, {'val_loss': 5570.9296875}, {'val_loss': 5570.9287109375}, {'val_loss': 5570.927734375}, {'val_loss': 5570.92822265625}, {'val_loss': 5570.93115234375}, {'val_loss': 5570.9296875}, {'val_loss': 5570.927734375}, {'val_loss': 5570.9287109375}, {'val_loss': 5570.9287109375}, {'val_loss': 5570.92822265625}, {'val_loss': 5570.92822265625}, {'val_loss': 5570.92822265625}, {'val_loss': 5570.92822265625}, {'val_loss': 5570.9287109375}, {'val_loss': 5570.9287109375}, {'val_loss': 5570.93017578125}, {'val_loss': 5570.93017578125}, {'val_loss': 5570.93212890625}, {'val_loss': 5570.93115234375}, {'val_loss': 5570.9296875}, {'val_loss': 5570.931640625}, {'val_loss': 5570.93359375}, {'val_loss': 5570.93310546875}, {'val_loss': 5570.93212890625}, {'val_loss': 5570.93505859375}, {'val_loss': 5570.93701171875}, {'val_loss': 5570.9375}, {'val_loss': 5570.93896484375}, {'val_loss': 5570.93798828125}, {'val_loss': 5570.935546875}, {'val_loss': 5570.93603515625}, {'val_loss': 5570.93701171875}, {'val_loss': 5570.935546875}, {'val_loss': 5570.93505859375}, {'val_loss': 5570.93408203125}, {'val_loss': 5570.93408203125}, {'val_loss': 5570.93505859375}, {'val_loss': 5570.93408203125}, {'val_loss': 5570.93310546875}, {'val_loss': 5570.93505859375}, {'val_loss': 5570.935546875}, {'val_loss': 5570.935546875}, {'val_loss': 5570.93603515625}, {'val_loss': 5570.93603515625}, {'val_loss': 5570.93505859375}, {'val_loss': 5570.93603515625}, {'val_loss': 5570.93359375}, {'val_loss': 5570.93701171875}, {'val_loss': 5570.93701171875}, {'val_loss': 5570.935546875}, {'val_loss': 5570.93359375}, {'val_loss': 5570.931640625}, {'val_loss': 5570.93310546875}, {'val_loss': 5570.93359375}, {'val_loss': 5570.93505859375}, {'val_loss': 5570.935546875}, {'val_loss': 5570.93701171875}, {'val_loss': 5570.93603515625}, {'val_loss': 5570.939453125}, {'val_loss': 5570.93896484375}, {'val_loss': 5570.93603515625}, {'val_loss': 5570.935546875}, {'val_loss': 5570.93505859375}, {'val_loss': 5570.93701171875}, {'val_loss': 5570.93896484375}, {'val_loss': 5570.93603515625}, {'val_loss': 5570.9375}, {'val_loss': 5570.93701171875}, {'val_loss': 5570.93701171875}, {'val_loss': 5570.93701171875}, {'val_loss': 5570.93603515625}, {'val_loss': 5570.935546875}, {'val_loss': 5570.93603515625}, {'val_loss': 5570.93701171875}, {'val_loss': 5570.935546875}, {'val_loss': 5570.935546875}, {'val_loss': 5570.93359375}, {'val_loss': 5570.93603515625}, {'val_loss': 5570.935546875}, {'val_loss': 5570.93505859375}, {'val_loss': 5570.93505859375}, {'val_loss': 5570.935546875}, {'val_loss': 5570.93408203125}, {'val_loss': 5570.935546875}, {'val_loss': 5570.93603515625}, {'val_loss': 5570.93603515625}, {'val_loss': 5570.93701171875}, {'val_loss': 5570.9375}, {'val_loss': 5570.93798828125}, {'val_loss': 5570.93798828125}, {'val_loss': 5570.93896484375}, {'val_loss': 5570.939453125}, {'val_loss': 5570.9375}, {'val_loss': 5570.93603515625}, {'val_loss': 5570.93603515625}, {'val_loss': 5570.9375}, {'val_loss': 5570.93603515625}, {'val_loss': 5570.935546875}, {'val_loss': 5570.93603515625}, {'val_loss': 5570.93701171875}, {'val_loss': 5570.93701171875}, {'val_loss': 5570.93701171875}, {'val_loss': 5570.9375}, {'val_loss': 5570.9375}, {'val_loss': 5570.93896484375}, {'val_loss': 5570.93798828125}, {'val_loss': 5570.9375}, {'val_loss': 5570.9375}, {'val_loss': 5570.9375}, {'val_loss': 5570.93408203125}, {'val_loss': 5570.935546875}, {'val_loss': 5570.93603515625}, {'val_loss': 5570.93603515625}, {'val_loss': 5570.93603515625}, {'val_loss': 5570.93701171875}, {'val_loss': 5570.93798828125}, {'val_loss': 5570.9375}, {'val_loss': 5570.93701171875}, {'val_loss': 5570.93798828125}, {'val_loss': 5570.939453125}, {'val_loss': 5570.93896484375}, {'val_loss': 5570.9375}, {'val_loss': 5570.9375}, {'val_loss': 5570.93896484375}, {'val_loss': 5570.93798828125}, {'val_loss': 5570.9375}, {'val_loss': 5570.93798828125}, {'val_loss': 5570.939453125}, {'val_loss': 5570.93994140625}, {'val_loss': 5570.939453125}, {'val_loss': 5570.93798828125}, {'val_loss': 5570.93896484375}, {'val_loss': 5570.93798828125}, {'val_loss': 5570.93896484375}, {'val_loss': 5570.93896484375}, {'val_loss': 5570.93896484375}, {'val_loss': 5570.939453125}, {'val_loss': 5570.93798828125}, {'val_loss': 5570.93896484375}, {'val_loss': 5570.939453125}, {'val_loss': 5570.939453125}, {'val_loss': 5570.93994140625}, {'val_loss': 5570.94091796875}, {'val_loss': 5570.939453125}, {'val_loss': 5570.93994140625}, {'val_loss': 5570.94140625}, {'val_loss': 5570.93994140625}, {'val_loss': 5570.94091796875}, {'val_loss': 5570.94140625}, {'val_loss': 5570.939453125}, {'val_loss': 5570.939453125}, {'val_loss': 5570.939453125}, {'val_loss': 5570.93994140625}, {'val_loss': 5570.94091796875}, {'val_loss': 5570.93994140625}, {'val_loss': 5570.94091796875}, {'val_loss': 5570.94140625}, {'val_loss': 5570.94140625}, {'val_loss': 5570.94140625}, {'val_loss': 5570.94189453125}, {'val_loss': 5570.94189453125}, {'val_loss': 5570.94287109375}, {'val_loss': 5570.94189453125}, {'val_loss': 5570.94482421875}, {'val_loss': 5570.94287109375}, {'val_loss': 5570.94287109375}, {'val_loss': 5570.94140625}, {'val_loss': 5570.94189453125}, {'val_loss': 5570.93994140625}, {'val_loss': 5570.94140625}, {'val_loss': 5570.93896484375}, {'val_loss': 5570.939453125}, {'val_loss': 5570.9375}, {'val_loss': 5570.93701171875}, {'val_loss': 5570.93603515625}, {'val_loss': 5570.935546875}, {'val_loss': 5570.93505859375}, {'val_loss': 5570.93408203125}, {'val_loss': 5570.93310546875}, {'val_loss': 5570.93310546875}, {'val_loss': 5570.931640625}, {'val_loss': 5570.93017578125}, {'val_loss': 5570.9296875}, {'val_loss': 5570.9296875}, {'val_loss': 5570.9287109375}, {'val_loss': 5570.927734375}, {'val_loss': 5570.9267578125}, {'val_loss': 5570.92578125}, {'val_loss': 5570.92626953125}, {'val_loss': 5570.92431640625}, {'val_loss': 5570.92431640625}, {'val_loss': 5570.923828125}, {'val_loss': 5570.92236328125}, {'val_loss': 5570.92236328125}, {'val_loss': 5570.92236328125}, {'val_loss': 5570.9228515625}, {'val_loss': 5570.9208984375}, {'val_loss': 5570.9208984375}, {'val_loss': 5570.919921875}, {'val_loss': 5570.919921875}, {'val_loss': 5570.919921875}, {'val_loss': 5570.91796875}, {'val_loss': 5570.91796875}, {'val_loss': 5570.91796875}, {'val_loss': 5570.91650390625}, {'val_loss': 5570.91650390625}, {'val_loss': 5570.91455078125}, {'val_loss': 5570.916015625}, {'val_loss': 5570.91455078125}, {'val_loss': 5570.9130859375}, {'val_loss': 5570.9130859375}, {'val_loss': 5570.91259765625}, {'val_loss': 5570.91259765625}, {'val_loss': 5570.91162109375}, {'val_loss': 5570.9111328125}, {'val_loss': 5570.9091796875}, {'val_loss': 5570.91064453125}, {'val_loss': 5570.90966796875}, {'val_loss': 5570.90771484375}, {'val_loss': 5570.90869140625}, {'val_loss': 5570.90771484375}, {'val_loss': 5570.90771484375}, {'val_loss': 5570.9072265625}, {'val_loss': 5570.90771484375}, {'val_loss': 5570.90673828125}, {'val_loss': 5570.90673828125}, {'val_loss': 5570.9052734375}, {'val_loss': 5570.90478515625}, {'val_loss': 5570.90478515625}, {'val_loss': 5570.90478515625}, {'val_loss': 5570.90380859375}, {'val_loss': 5570.90283203125}, {'val_loss': 5570.90283203125}, {'val_loss': 5570.90478515625}, {'val_loss': 5570.90185546875}, {'val_loss': 5570.90185546875}, {'val_loss': 5570.90087890625}, {'val_loss': 5570.90087890625}, {'val_loss': 5570.90087890625}, {'val_loss': 5570.90087890625}, {'val_loss': 5570.8994140625}, {'val_loss': 5570.8994140625}, {'val_loss': 5570.89892578125}, {'val_loss': 5570.8994140625}, {'val_loss': 5570.89892578125}, {'val_loss': 5570.89794921875}, {'val_loss': 5570.896484375}, {'val_loss': 5570.89599609375}, {'val_loss': 5570.89599609375}, {'val_loss': 5570.89599609375}, {'val_loss': 5570.8955078125}, {'val_loss': 5570.89453125}, {'val_loss': 5570.89453125}, {'val_loss': 5570.89404296875}, {'val_loss': 5570.89404296875}, {'val_loss': 5570.89453125}, {'val_loss': 5570.89404296875}, {'val_loss': 5570.8935546875}, {'val_loss': 5570.8916015625}, {'val_loss': 5570.89208984375}, {'val_loss': 5570.8916015625}, {'val_loss': 5570.890625}, {'val_loss': 5570.890625}, {'val_loss': 5570.890625}, {'val_loss': 5570.890625}, {'val_loss': 5570.890625}, {'val_loss': 5570.890625}, {'val_loss': 5570.89013671875}, {'val_loss': 5570.89013671875}, {'val_loss': 5570.89013671875}, {'val_loss': 5570.89013671875}, {'val_loss': 5570.89013671875}, {'val_loss': 5570.8896484375}, {'val_loss': 5570.88818359375}, {'val_loss': 5570.888671875}, {'val_loss': 5570.88818359375}, {'val_loss': 5570.888671875}, {'val_loss': 5570.8896484375}, {'val_loss': 5570.8876953125}, {'val_loss': 5570.88818359375}, {'val_loss': 5570.8876953125}, {'val_loss': 5570.88818359375}, {'val_loss': 5570.88818359375}, {'val_loss': 5570.8876953125}, {'val_loss': 5570.88671875}, {'val_loss': 5570.88623046875}, {'val_loss': 5570.88671875}, {'val_loss': 5570.88671875}, {'val_loss': 5570.88623046875}, {'val_loss': 5570.88623046875}, {'val_loss': 5570.884765625}, {'val_loss': 5570.884765625}, {'val_loss': 5570.884765625}, {'val_loss': 5570.884765625}, {'val_loss': 5570.884765625}, {'val_loss': 5570.884765625}, {'val_loss': 5570.88427734375}, {'val_loss': 5570.8837890625}, {'val_loss': 5570.88427734375}, {'val_loss': 5570.88427734375}, {'val_loss': 5570.88427734375}, {'val_loss': 5570.8837890625}, {'val_loss': 5570.8837890625}, {'val_loss': 5570.88232421875}, {'val_loss': 5570.88134765625}, {'val_loss': 5570.88134765625}, {'val_loss': 5570.88232421875}, {'val_loss': 5570.880859375}, {'val_loss': 5570.88134765625}, {'val_loss': 5570.880859375}, {'val_loss': 5570.880859375}, {'val_loss': 5570.88037109375}, {'val_loss': 5570.88037109375}, {'val_loss': 5570.87939453125}, {'val_loss': 5570.88037109375}, {'val_loss': 5570.88037109375}, {'val_loss': 5570.87939453125}, {'val_loss': 5570.87939453125}, {'val_loss': 5570.87841796875}, {'val_loss': 5570.87841796875}, {'val_loss': 5570.87890625}, {'val_loss': 5570.87841796875}, {'val_loss': 5570.87841796875}, {'val_loss': 5570.87841796875}, {'val_loss': 5570.87744140625}, {'val_loss': 5570.87744140625}, {'val_loss': 5570.876953125}, {'val_loss': 5570.87744140625}, {'val_loss': 5570.876953125}, {'val_loss': 5570.87646484375}, {'val_loss': 5570.875}, {'val_loss': 5570.875}, {'val_loss': 5570.87451171875}, {'val_loss': 5570.87548828125}, {'val_loss': 5570.87646484375}, {'val_loss': 5570.87548828125}, {'val_loss': 5570.875}, {'val_loss': 5570.875}, {'val_loss': 5570.875}, {'val_loss': 5570.875}, {'val_loss': 5570.87451171875}, {'val_loss': 5570.87353515625}, {'val_loss': 5570.873046875}, {'val_loss': 5570.87353515625}, {'val_loss': 5570.873046875}, {'val_loss': 5570.87451171875}, {'val_loss': 5570.873046875}, {'val_loss': 5570.873046875}, {'val_loss': 5570.873046875}, {'val_loss': 5570.87255859375}, {'val_loss': 5570.87158203125}, {'val_loss': 5570.87109375}, {'val_loss': 5570.87060546875}, {'val_loss': 5570.86962890625}, {'val_loss': 5570.87109375}, {'val_loss': 5570.87109375}, {'val_loss': 5570.87109375}, {'val_loss': 5570.87109375}, {'val_loss': 5570.87060546875}, {'val_loss': 5570.86962890625}, {'val_loss': 5570.86962890625}, {'val_loss': 5570.86962890625}, {'val_loss': 5570.869140625}, {'val_loss': 5570.86767578125}, {'val_loss': 5570.869140625}, {'val_loss': 5570.86865234375}, {'val_loss': 5570.86865234375}, {'val_loss': 5570.869140625}, {'val_loss': 5570.86865234375}, {'val_loss': 5570.86865234375}, {'val_loss': 5570.86865234375}, {'val_loss': 5570.8662109375}, {'val_loss': 5570.8671875}, {'val_loss': 5570.8671875}, {'val_loss': 5570.865234375}, {'val_loss': 5570.865234375}, {'val_loss': 5570.865234375}, {'val_loss': 5570.8662109375}, {'val_loss': 5570.865234375}, {'val_loss': 5570.865234375}, {'val_loss': 5570.865234375}, {'val_loss': 5570.865234375}, {'val_loss': 5570.865234375}, {'val_loss': 5570.865234375}, {'val_loss': 5570.86376953125}, {'val_loss': 5570.86376953125}, {'val_loss': 5570.8623046875}, {'val_loss': 5570.86328125}, {'val_loss': 5570.86181640625}, {'val_loss': 5570.86328125}, {'val_loss': 5570.86328125}, {'val_loss': 5570.86181640625}, {'val_loss': 5570.8623046875}, {'val_loss': 5570.86181640625}, {'val_loss': 5570.8603515625}, {'val_loss': 5570.8603515625}, {'val_loss': 5570.861328125}, {'val_loss': 5570.859375}, {'val_loss': 5570.861328125}, {'val_loss': 5570.861328125}, {'val_loss': 5570.85986328125}, {'val_loss': 5570.861328125}, {'val_loss': 5570.8603515625}, {'val_loss': 5570.85986328125}, {'val_loss': 5570.859375}, {'val_loss': 5570.859375}, {'val_loss': 5570.859375}, {'val_loss': 5570.859375}, {'val_loss': 5570.8583984375}, {'val_loss': 5570.8583984375}, {'val_loss': 5570.859375}, {'val_loss': 5570.859375}, {'val_loss': 5570.859375}, {'val_loss': 5570.859375}, {'val_loss': 5570.85791015625}, {'val_loss': 5570.8564453125}]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'losses')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jA9E2P4KLWmt",
        "colab_type": "text"
      },
      "source": [
        "Let's log the final validation loss to Jovian and commit the notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZX2aDswLWmu",
        "colab_type": "code",
        "outputId": "9fbc518e-531c-4595-a1b0-43e85e1d9db7",
        "colab": {}
      },
      "source": [
        "jovian.log_metrics(val_loss=val_loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[jovian] Metrics logged.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLTG3-OtLWmy",
        "colab_type": "code",
        "outputId": "4ffd84a9-5d97-4d13-e777-1b37821de797",
        "colab": {}
      },
      "source": [
        "jovian.commit(project=project_name, environment=None)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[jovian] Attempting to save notebook..\u001b[0m\n",
            "[jovian] Updating notebook \"lokeshpara/02-insurance-linear-regression\" on https://jovian.ml/\u001b[0m\n",
            "[jovian] Uploading notebook..\u001b[0m\n",
            "[jovian] Attaching records (metrics, hyperparameters, dataset etc.)\u001b[0m\n",
            "[jovian] Committed successfully! https://jovian.ml/lokeshpara/02-insurance-linear-regression\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://jovian.ml/lokeshpara/02-insurance-linear-regression'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiKtx2uWLWm0",
        "colab_type": "text"
      },
      "source": [
        "Now scroll back up, re-initialize the model, and try different set of values for batch size, number of epochs, learning rate etc. Commit each experiment and use the \"Compare\" and \"View Diff\" options on Jovian to compare the different results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSg9xQ0KLWm0",
        "colab_type": "text"
      },
      "source": [
        "## Step 5: Make predictions using the trained model\n",
        "\n",
        "**Q: Complete the following function definition to make predictions on a single input**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hX-MWyHxLWm1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_single(input, target, model):\n",
        "    inputs = input.unsqueeze(0)\n",
        "    predictions = model(inputs)                 # fill this\n",
        "    prediction = predictions[0].detach()\n",
        "    print(\"Input:\", input)\n",
        "    print(\"Target:\", target)\n",
        "    print(\"Prediction:\", prediction)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wam8px4ALWm6",
        "colab_type": "code",
        "outputId": "d5b8231f-8d00-48bb-ea00-099e62292b24",
        "colab": {}
      },
      "source": [
        "input, target = val_ds[3]\n",
        "predict_single(input, target, model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: tensor([24.0000,  1.0000, 31.6350,  2.0000,  0.0000])\n",
            "Target: tensor([3785.3423])\n",
            "Prediction: tensor([4049.6191])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vS4VC3OLWm_",
        "colab_type": "code",
        "outputId": "76cfee9b-b7a7-42a8-ad2b-215aad99a846",
        "colab": {}
      },
      "source": [
        "input, target = val_ds[10]\n",
        "predict_single(input, target, model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: tensor([21.0000,  0.0000, 37.3293,  2.0000,  0.0000])\n",
            "Target: tensor([3830.4167])\n",
            "Prediction: tensor([3325.9941])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrBrUDCdLWnG",
        "colab_type": "code",
        "outputId": "94c07508-05af-4425-ca9b-9ed0b9a01406",
        "colab": {}
      },
      "source": [
        "input, target = val_ds[15]\n",
        "predict_single(input, target, model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: tensor([20.0000,  0.0000, 32.1623,  0.0000,  0.0000])\n",
            "Target: tensor([2415.4985])\n",
            "Prediction: tensor([2595.4756])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTyFbLPpLWnL",
        "colab_type": "text"
      },
      "source": [
        "Are you happy with your model's predictions? Try to improve them further."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqRjqKGPLWnN",
        "colab_type": "text"
      },
      "source": [
        "## (Optional) Step 6: Try another dataset & blog about it\n",
        "\n",
        "While this last step is optional for the submission of your assignment, we highly recommend that you do it. Try to clean up & replicate this notebook (or [this one](https://jovian.ml/aakashns/housing-linear-minimal), or [this one](https://jovian.ml/aakashns/mnist-logistic-minimal) ) for a different linear regression or logistic regression problem. This will help solidify your understanding, and give you a chance to differentiate the generic patters in machine learning from problem-specific details.\n",
        "\n",
        "Here are some sources to find good datasets:\n",
        "\n",
        "- https://lionbridge.ai/datasets/10-open-datasets-for-linear-regression/\n",
        "- https://www.kaggle.com/rtatman/datasets-for-regression-analysis\n",
        "- https://archive.ics.uci.edu/ml/datasets.php?format=&task=reg&att=&area=&numAtt=&numIns=&type=&sort=nameUp&view=table\n",
        "- https://people.sc.fsu.edu/~jburkardt/datasets/regression/regression.html\n",
        "- https://archive.ics.uci.edu/ml/datasets/wine+quality\n",
        "- https://pytorch.org/docs/stable/torchvision/datasets.html\n",
        "\n",
        "We also recommend that you write a blog about your approach to the problem. Here is a suggested structure for your post (feel free to experiment with it):\n",
        "\n",
        "- Interesting title & subtitle\n",
        "- Overview of what the blog covers (which dataset, linear regression or logistic regression, intro to PyTorch)\n",
        "- Downloading & exploring the data\n",
        "- Preparing the data for training\n",
        "- Creating a model using PyTorch\n",
        "- Training the model to fit the data\n",
        "- Your thoughts on how to experiment with different hyperparmeters to reduce loss\n",
        "- Making predictions using the model\n",
        "\n",
        "As with the previous assignment, you can [embed Juptyer notebook cells & outputs from Jovian](https://medium.com/jovianml/share-and-embed-jupyter-notebooks-online-with-jovian-ml-df709a03064e) into your blog. \n",
        "\n",
        "Don't forget to share your work on the forum: https://jovian.ml/forum/t/share-your-work-here-assignment-2/4931"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeO07enzLWnO",
        "colab_type": "code",
        "outputId": "6ff633de-6c2b-4e76-b4d5-9e674bfcae3f",
        "colab": {}
      },
      "source": [
        "jovian.commit(project=project_name, environment=None)\n",
        "jovian.commit(project=project_name, environment=None) # try again, kaggle fails sometimes"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[jovian] Attempting to save notebook..\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MycQ-ms6LWnV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}